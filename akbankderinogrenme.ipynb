{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":2431805,"sourceType":"datasetVersion","datasetId":8782}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## 1) Ortam Kurulumu ve Tekrarlanabilirlik\n\nBu hücre, derin öğrenme projelerine başlamadan önce **çalışma ortamını hazırlar ve sonuçların tekrarlanabilir olmasını sağlar.**\n\n- **Kütüphaneler**: `os`, `random`, `numpy`, `tensorflow` modülleri içe aktarılır.  \n- **Log düzeni**: `os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"` ile TensorFlow’un gereksiz uyarı ve bilgi mesajları gizlenir.  \n- **Rastgelelik sabitleme**: `random.seed`, `np.random.seed` ve `tf.random.set_seed` komutları ile tüm rastgele işlemler aynı başlangıç değerine bağlanır. Bu sayede her çalıştırmada aynı sonuçlar alınabilir (**reproducibility**).  \n- **GPU bellek yönetimi**: `tf.config.experimental.set_memory_growth` ile TensorFlow GPU belleğini ihtiyaç oldukça kullanır, ilk başta tamamını rezerve etmez. Bu, bellek taşma (OOM) hatalarını önlemeye yardımcı olur.  \n- **Durum bildirimi**: Mevcut fiziksel GPU sayısı ekrana yazdırılır; `0` görülürse işlem CPU üzerinden yapılır.\n\n> Bu hücre sayesinde **temiz, düzenli ve öngörülebilir bir çalışma ortamı** oluşturulur.\n","metadata":{}},{"cell_type":"code","source":"import os, random, numpy as np, tensorflow as tf\n\nos.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\nSEED = 42\nrandom.seed(SEED); np.random.seed(SEED); tf.random.set_seed(SEED)\ngpus = tf.config.list_physical_devices('GPU')\nfor g in gpus:\n    try: tf.config.experimental.set_memory_growth(g, True)\n    except: pass\nprint(\"GPU sayısı:\", len(gpus))\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-25T21:02:48.840977Z","iopub.execute_input":"2025-09-25T21:02:48.841636Z","iopub.status.idle":"2025-09-25T21:03:09.007141Z","shell.execute_reply.started":"2025-09-25T21:02:48.841612Z","shell.execute_reply":"2025-09-25T21:03:09.006304Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 2) Veri Yollarının Belirlenmesi ve Keşif (Data Paths & Exploration)\n\nBu hücrede **görüntü verisinin yolu belirlenir, dosyalar listelenir ve eğitim/validasyon/test ayrımı yapılır.**\n\n- **Kütüphaneler**:  \n  - `pandas`: Veri çerçevesi (DataFrame) oluşturma ve düzenleme için.  \n  - `pathlib.Path`: Dosya yollarını platformdan bağımsız biçimde yönetmek için.  \n\n- **Veri konumu**: `DATA_DIR` ile Kaggle’ın *flowers-recognition* veri kümesindeki kök klasör tanımlanır. Alt klasörler çiçek sınıflarını (örneğin *rose*, *daisy*) temsil eder.\n\n- **Dosya listesi çıkarma**:  \n  - `glob` yöntemi ile `*.jpg`, `*.jpeg`, `*.png` uzantılı tüm görüntüler bulunur.  \n  - Her bir dosyanın tam yolu `paths`, dosyanın klasör adı ise (etiket) `labels` listesine kaydedilir.\n\n- **Veri çerçevesi**: `df` adlı DataFrame’de her satırda bir görüntü yolu ve buna karşılık gelen etiket bulunur.  \n  - `sample(frac=1, random_state=SEED)` verileri karıştırır.  \n  - `reset_index(drop=True)` ile yeni bir düzenli indeks oluşturulur.\n\n- **Eğitim / Doğrulama / Test bölünmesi**:  \n  - `train_test_split` ile verinin %15’i test kümesi olarak ayrılır.  \n  - Kalan %85’in içinden tekrar bölünerek yaklaşık %15’i validasyon için ayrılır.  \n  - `stratify` parametresi, her sınıftaki oranın tüm alt kümelerde korunmasını sağlar.\n\n- **Sınıf bilgisi**:  \n  - `classes`: Tüm çiçek sınıflarının alfabetik listesi.  \n  - `class_to_idx`: Her sınıfa bir numara atayan sözlük.  \n  - `num_classes`: Toplam sınıf sayısı.\n\n- **Kontrol çıktıları**:  \n  - Toplam görüntü sayısı (`len(all_images)`).  \n  - Bulunan sınıflar listesi (`classes`).\n\n> Bu hücre sayesinde **ham görsel veriler düzenlenir, etiketlenir ve model eğitimine hazır hale gelir**.\n","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom pathlib import Path\n\nDATA_DIR = Path(\"/kaggle/input/flowers-recognition/flowers\") \nall_images = []\nfor ext in (\"*.jpg\",\"*.jpeg\",\"*.png\"): all_images += list(DATA_DIR.glob(f\"*/*{ext[1:]}\"))\nprint(\"Görüntü sayısı:\", len(all_images))\n\npaths  = [str(p) for p in all_images]\nlabels = [p.parent.name for p in all_images]\ndf = pd.DataFrame({\"path\": paths, \"label\": labels}).sample(frac=1, random_state=SEED).reset_index(drop=True)\n\nfrom sklearn.model_selection import train_test_split\ntrain_df, test_df = train_test_split(df, test_size=0.15, random_state=SEED, stratify=df[\"label\"])\ntrain_df, val_df  = train_test_split(train_df, test_size=0.15/(1-0.15), random_state=SEED, stratify=train_df[\"label\"])\n\nclasses = sorted(df[\"label\"].unique())\nclass_to_idx = {c:i for i,c in enumerate(classes)}\nnum_classes = len(classes)\nprint(\"Sınıflar:\", classes)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T21:03:23.823145Z","iopub.execute_input":"2025-09-25T21:03:23.823665Z","iopub.status.idle":"2025-09-25T21:03:24.182320Z","shell.execute_reply.started":"2025-09-25T21:03:23.823643Z","shell.execute_reply":"2025-09-25T21:03:24.181752Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 3) Eğitim Verisinin Sınıf Dağılımı\n\nBu hücre, eğitim kümesindeki her çiçek sınıfının kaç örneğe sahip olduğunu **çubuk grafik** ile gösterir.\n\n- `value_counts().plot(kind=\"bar\")` → Her sınıfın görüntü sayısını bar grafiğe döker.  \n- `figsize`, `color`, `edgecolor` → Grafik boyutu ve renk ayarları.  \n- `set_title`, `set_xlabel`, `set_ylabel` → Başlık ve eksen isimleri.  \n- `xticks(rotation=45)` → Sınıf adlarını eğerek okunabilirlik sağlar.\n\n> Veri dengesini hızlıca görmek ve olası dengesizlikleri fark etmek için kullanılır.\n","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nfig, ax = plt.subplots(figsize=(8,5))\ntrain_df[\"label\"].value_counts().plot(kind=\"bar\", ax=ax, color=\"skyblue\", edgecolor=\"black\")\nax.set_title(\"Train Set – Sınıf Dağılımı\")\nax.set_xlabel(\"Sınıf\")\nax.set_ylabel(\"Görüntü Sayısı\")\nplt.xticks(rotation=45)\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T21:03:28.828579Z","iopub.execute_input":"2025-09-25T21:03:28.829282Z","iopub.status.idle":"2025-09-25T21:03:29.186290Z","shell.execute_reply.started":"2025-09-25T21:03:28.829258Z","shell.execute_reply":"2025-09-25T21:03:29.185579Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 4) Eğitim Setinden Rastgele Görseller\n\nBu hücre, eğitim kümesinden **rastgele 15 görseli** tablo şeklinde gösterir.\n\n- `random.sample` → Eğitim verisinden 15 rastgele dosya yolu seçer.  \n- `Image.open` → Her görüntüyü okur ve ekranda gösterir.  \n- `plt.subplots(3,5)` → 3 satır 5 sütunlu bir figür alanı oluşturur.  \n- `ax.imshow` → Görüntüyü ilgili eksene çizer.  \n- `ax.set_title` → Her görselin üstüne sınıf adını (etiketini) yazar.  \n- `ax.axis(\"off\")` → Eksen çizgilerini kaldırır.  \n- `plt.suptitle` ve `plt.tight_layout` → Genel başlık ekler, kenar boşluklarını düzenler.\n\n> Veri setinin içeriğini hızlıca gözden geçirip **görsellerin çeşitliliğini ve etiketlerin doğruluğunu** kontrol etmek için kullanılır.\n","metadata":{}},{"cell_type":"code","source":"import random\nfrom PIL import Image\n\nfig, axes = plt.subplots(3, 5, figsize=(12,7))\nsample_paths = random.sample(train_df[\"path\"].tolist(), 15)\n\nfor ax, img_path in zip(axes.flat, sample_paths):\n    img = Image.open(img_path)\n    ax.imshow(img)\n    ax.set_title(Path(img_path).parent.name, fontsize=8)\n    ax.axis(\"off\")\n\nplt.suptitle(\"Train Set – Rastgele 15 Görsel\", fontsize=14)\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T21:03:33.601734Z","iopub.execute_input":"2025-09-25T21:03:33.602282Z","iopub.status.idle":"2025-09-25T21:03:34.846520Z","shell.execute_reply.started":"2025-09-25T21:03:33.602258Z","shell.execute_reply":"2025-09-25T21:03:34.845487Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 5) Görsel Veri Seti Hazırlığı ve Veri Artırma (Data Augmentation)\n\nBu hücre, resimleri **modele uygun formata çevirir** ve eğitim sırasında **veri artırma (data augmentation)** ile modeli genelleştirme gücü yüksek hale getirir.\n\n### 5.1) Temel Ayarlar\n- **IMG_SIZE = 224** → EfficientNet gibi çoğu önceden eğitilmiş modelin beklediği standart giriş boyutu.  \n- **BATCH = 32** → Her eğitim adımında işlenecek görüntü sayısı.  \n- **AUTO = tf.data.AUTOTUNE** → TensorFlow, veri yükleme ve önbellekleme işlerini otomatik en iyi performansla yürütür.\n\n### 5.2) Görseli Okuma ve Ön İşleme\n`decode_and_resize(path, label_idx)`  \n- Dosya yolundaki resmi okur (`tf.io.read_file`), RGB kanallarına çevirir (`decode_image`).\n- Boyutunu 224×224 piksele yeniden boyutlandırır (`tf.image.resize`).\n- Piksel değerlerini `float32` tipine çevirir ve `preprocess_input` ile **[-1,1] aralığına** normalize eder.\n- Etiketi `one-hot` formuna dönüştürür (örneğin 5 sınıf varsa `[0,1,0,0,0]` gibi).\n\n### 5.3) Veri Artırma Katmanı (Data Augmentation)\n`aug` → `keras.Sequential` ile oluşturulan dönüşümler:\n- `layers.RandomFlip(mode=\"horizontal\")` → Görüntüyü rastgele yatay çevirir.  \n- `layers.RandomRotation(factor=0.08)` → Maksimum ±%8 oranında döndürür.  \n- `layers.RandomZoom(height_factor=0.1, width_factor=0.1)` → Yükseklik ve genişlikte %10’a kadar yakınlaştırır.  \n- `layers.RandomContrast(factor=0.1)` → Kontrastı %10 oranında değiştirir.  \n\n> **Amaç**: Modelin tek tip veriye aşırı uyum sağlamasını (overfitting) önlemek, gerçek dünyadaki konum, ışık ve poz değişikliklerine karşı **daha dayanıklı** hale getirmek.\n\n### 5.4) Veri Kümesi Oluşturma\n`make_ds(frame, training=False)`  \n- DataFrame’den dosya yolları ve etiketleri alır.  \n- Eğitim modundaysa veriyi her epoch’ta rastgele karıştırır.  \n- Görselleri `decode_and_resize` ile işler, eğitim modunda `augment_if_training` ile veri artırır.  \n- Veriyi `batch` ve `prefetch` ile hızlandırır.\n\n### 5.5) Sonuç Dataset’leri\n- `train_ds` → Veri artırma uygulanmış eğitim kümesi.  \n- `val_ds`   → Doğrulama (modeli değerlendirirken veri artırma yok).  \n- `test_ds`  → Test kümesi.\n\n> Bu adım, görselleri **standart boyut ve ölçeğe getirir**, veri artırma ile çeşitlendirir ve modeli **daha kararlı ve genelleme yeteneği yüksek** hale getirir.\n","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.applications.efficientnet import preprocess_input\nfrom tensorflow.keras import layers\n\nIMG_SIZE = 224\nBATCH    = 32\nAUTO     = tf.data.AUTOTUNE\n\ndef decode_and_resize(path, label_idx):\n    img = tf.io.read_file(path)\n    img = tf.io.decode_image(img, channels=3, expand_animations=False)\n    img = tf.image.resize(img, (IMG_SIZE, IMG_SIZE), method=tf.image.ResizeMethod.BILINEAR)\n    img = tf.cast(img, tf.float32)\n    img = preprocess_input(img)   # [-1,1]\n    y = tf.one_hot(label_idx, depth=num_classes)\n    return img, y\n\naug = tf.keras.Sequential(\n    [\n        layers.RandomFlip(mode=\"horizontal\"),     \n        layers.RandomRotation(factor=0.08),        \n        layers.RandomZoom(height_factor=0.1, width_factor=0.1),\n        layers.RandomContrast(factor=0.1),\n    ], name=\"augment\")\n\ndef augment_if_training(img, y):\n    return aug(img, training=True), y\n\ndef make_ds(frame, training=False):\n    paths = frame[\"path\"].values\n    labs  = frame[\"label\"].map(class_to_idx).values\n    ds = tf.data.Dataset.from_tensor_slices((paths, labs))\n    if training: ds = ds.shuffle(len(frame), seed=SEED, reshuffle_each_iteration=True)\n    ds = ds.map(decode_and_resize, num_parallel_calls=AUTO)\n    if training: ds = ds.map(augment_if_training, num_parallel_calls=AUTO)\n    ds = ds.batch(BATCH).prefetch(AUTO)\n    return ds\n\ntrain_ds = make_ds(train_df, training=True)\nval_ds   = make_ds(val_df,   training=False)\ntest_ds  = make_ds(test_df,  training=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T21:03:40.634217Z","iopub.execute_input":"2025-09-25T21:03:40.634500Z","iopub.status.idle":"2025-09-25T21:03:43.160706Z","shell.execute_reply.started":"2025-09-25T21:03:40.634479Z","shell.execute_reply":"2025-09-25T21:03:43.160162Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 6) Veri Artırma (Augmentation) Sonuçlarının Görselleştirilmesi\n\nBu hücre, eğitim kümesinden alınan bir batch (toplu) veride **uygulanmış rastgele artırma işlemlerini** görsel olarak gösterir.\n\n- `train_ds.take(1)` → Eğitim veri kümesinden tek bir batch çeker.  \n- `x_aug` → Veri artırma uygulanmış görüntüler; `numpy().astype(np.uint8)` ile görüntü formatına dönüştürülür.  \n- `k = min(8, x_show.shape[0])` → İlk 8 görüntü seçilir.  \n- `plt.subplot(2,4,i+1)` ve `plt.imshow` → 2 satır 4 sütunlu bir tabloya her görüntü yerleştirilir.  \n- `plt.axis('off')` → Eksen çizgileri kaldırılır.  \n- `plt.suptitle` ve `plt.tight_layout` → Genel başlık ekler, düzenli görünüm sağlar.\n\n> Bu görselleştirme ile **RandomFlip, RandomRotation, RandomZoom, RandomContrast** gibi veri artırma adımlarının resimlere nasıl uygulandığı doğrudan görülebilir.\n","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\n\nfor x_aug, yb in train_ds.take(1):\n    x_show = x_aug.numpy().astype(np.uint8)\n    break\n\nk = min(8, x_show.shape[0])\nplt.figure(figsize=(12,6))\nfor i in range(k):\n    plt.subplot(2,4,i+1)\n    plt.imshow(x_show[i])\n    plt.axis('off')\nplt.suptitle(\"Augmentation örnekleri\")\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T21:03:51.948330Z","iopub.execute_input":"2025-09-25T21:03:51.948919Z","iopub.status.idle":"2025-09-25T21:03:52.980331Z","shell.execute_reply.started":"2025-09-25T21:03:51.948896Z","shell.execute_reply":"2025-09-25T21:03:52.979428Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 7) Model Kurulumu, Derleme ve Callback’ler\n\nBu hücre, **EfficientNetB0 tabanlı bir transfer öğrenme modeli** kurar, uygun kayıp/optimizasyon ayarlarıyla derler ve eğitimde kullanılacak **callback**’leri hazırlar.\n\n### 🔩 Mimari (Transfer Learning)\n- `EfficientNetB0(include_top=False, weights=\"imagenet\")`  \n  - **Ön-eğitimli** (ImageNet) taban; tepe (classification) katmanı çıkarılmıştır.\n\n- Akış:\n  1. **Input**: `(224,224,3)`\n  2. **base(inputs, training=False)**: BatchNorm dalgalanmalarını önlemek için çıkarım modunda çağrılır.\n  3. **GlobalAveragePooling2D**: Özellik haritalarını vektöre indirger, parametre sayısını azaltır.\n  4. **Dropout(0.4)**: Aşırı uyumu (overfitting) azaltır.\n  5. **Dense(num_classes, softmax)**: Sınıf olasılıklarını üretir.  \n     - `l2` verilirse `kernel_regularizer=l2(...)` ile **ağırlık cezalandırma** eklenir.\n\n### 🧪 Derleme (Loss & Optimizer)\n- **Loss**: `CategoricalCrossentropy(label_smoothing=...)`  \n  - `label_smoothing`: Çok güvenli tahminleri yumuşatır, genellemeye yardımcı olabilir (varsayılan 0.0).\n- **Optimizer**:  \n  - `\"adam\"` → `Adam(lr)`: Hızlı yakınsama, genelde iyi varsayılan.  \n  - Aksi halde `SGD(lr, momentum=0.9, nesterov=True)`: Daha kontrollü güncellemeler.\n\n### ⏱️ Callback’ler\n- `ModelCheckpoint(\"best_stage1.keras\", monitor=\"val_accuracy\", mode=\"max\", save_best_only=True)`  \n  - **En iyi doğrulama başarımı** yakalandığında ağırlıkları kaydeder (Stage-1).  \n- `EarlyStopping(monitor=\"val_accuracy\", patience=5, restore_best_weights=True)`  \n  - İyileşme durunca eğitimi erken durdurur; **en iyi ağırlıklara** geri döner.\n- `ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=2, min_lr=1e-7)`  \n  - Kayıp iyileşmiyorsa öğrenme oranını **yarıya indirir** (plateau’da daha ince ayar).\n\n### ▶️ Stage-1 Eğitimi\n- `build_model(dropout=0.4, base_trainable=False)` ile tabanı dondurulmuş model kurulur.  \n- `compile_with(model, lr=1e-3, opt=\"adam\")` ile uygun öğrenme oranı ve optimizer ayarlanır.  \n- `model.summary()` mimariyi özetler.","metadata":{}},{"cell_type":"code","source":"\nfrom tensorflow.keras import layers, models, regularizers\nfrom tensorflow.keras.applications import EfficientNetB0\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n\ndef build_model(dropout=0.4, l2=None, base_trainable=False):\n    base = EfficientNetB0(include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3), weights=\"imagenet\")\n    base.trainable = base_trainable\n    inputs = layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3), name=\"input_preprocessed\")\n    x = base(inputs, training=False)\n    x = layers.GlobalAveragePooling2D()(x)\n    x = layers.Dropout(dropout)(x)\n    kw = {} if l2 is None else {\"kernel_regularizer\": regularizers.l2(l2)}\n    outputs = layers.Dense(num_classes, activation=\"softmax\", **kw)(x)\n    return models.Model(inputs, outputs, name=\"flowers_effnetb0\")\n\ndef compile_with(model, lr, opt=\"adam\", label_smoothing=0.0):\n    loss = tf.keras.losses.CategoricalCrossentropy(label_smoothing=label_smoothing)\n    optimizer = tf.keras.optimizers.Adam(lr) if opt==\"adam\" else tf.keras.optimizers.SGD(lr, momentum=0.9, nesterov=True)\n    model.compile(optimizer=optimizer, loss=loss, metrics=[\"accuracy\"])\n    return model\n\nckpt1 = ModelCheckpoint(\"best_stage1.keras\", monitor=\"val_accuracy\", save_best_only=True, mode=\"max\")\nes    = EarlyStopping(monitor=\"val_accuracy\", patience=5, restore_best_weights=True)\nrlr   = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=2, min_lr=1e-7)\nmodel = build_model(dropout=0.4, base_trainable=False)\ncompile_with(model, lr=1e-3, opt=\"adam\")\nprint(model.summary())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T21:04:01.840634Z","iopub.execute_input":"2025-09-25T21:04:01.840884Z","iopub.status.idle":"2025-09-25T21:04:04.008691Z","shell.execute_reply.started":"2025-09-25T21:04:01.840868Z","shell.execute_reply":"2025-09-25T21:04:04.008161Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 8) Model Mimarisi Görselleştirme\n\nBu hücre, kurulmuş olan **derin öğrenme modelinin yapısını resim dosyası olarak kaydeder**.\n\n- `plot_model(model, to_file=\"model_architecture.png\")` → Model mimarisini `model_architecture.png` adıyla kaydeder.  \n- `show_shapes=True` → Her katmanın giriş/çıkış boyutlarını gösterir.  \n- `show_layer_names=True` → Katman isimlerini diyagrama ekler.\n","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.utils import plot_model\n\nplot_model(model, to_file=\"model_architecture.png\",\n           show_shapes=True, show_layer_names=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T21:04:08.740800Z","iopub.execute_input":"2025-09-25T21:04:08.741412Z","iopub.status.idle":"2025-09-25T21:04:08.996899Z","shell.execute_reply.started":"2025-09-25T21:04:08.741386Z","shell.execute_reply":"2025-09-25T21:04:08.996141Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 9) Model Eğitimi\n\nBu hücre, EfficientNet tabanlı modelin **sınıflandırma katmanlarını eğitir.** \n\n- **`model.fit` parametreleri**  \n  - `train_ds` → Eğitim verisi.  \n  - `validation_data=val_ds` → Her epoch sonunda doğrulama kümesinde ölçüm yapılır.  \n  - `epochs=15` → Maksimum 15 eğitim turu.  \n  - `callbacks=[ckpt1, es, rlr]` →  \n    - `ckpt1`: En iyi doğrulama doğruluğunda modeli kaydeder.  \n    - `es`: İyileşme durursa erken durdurur ve en iyi ağırlıkları geri yükler.  \n    - `rlr`: Doğrulama kaybı iyileşmezse öğrenme oranını otomatik yarıya indirir.\n  - `verbose=1` → Her epoch için ilerleme çubuğu ve metrikler gösterilir.\n\n- **`hist1` çıktısı**  \n  - Eğitim süresince **kayıp (loss)** ve **doğruluk (accuracy)** değerlerini kaydeder.  \n  - Bu bilgiler, sonraki adımda grafik çizerek modelin **öğrenme eğrisini** incelemek için kullanılır.\n\n> Bu aşama, önceden eğitilmiş EfficientNet tabanını değiştirmeden  üst sınıflandırıcı katmanını eğiterek **hızlı ve stabil bir eğitim yapılabilmesini sağlar**.\n","metadata":{}},{"cell_type":"code","source":"hist1 = model.fit(\n    train_ds,\n    validation_data=val_ds,\n    epochs=15,\n    callbacks=[ckpt1, es, rlr],\n    verbose=1\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T21:04:16.278879Z","iopub.execute_input":"2025-09-25T21:04:16.279184Z","iopub.status.idle":"2025-09-25T21:09:41.658845Z","shell.execute_reply.started":"2025-09-25T21:04:16.279158Z","shell.execute_reply":"2025-09-25T21:09:41.658029Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 10) Öğrenme Eğrileri (Kısa, Net, Detaylı)\n\n**Amaç**\n- Eğitim/validasyon **accuracy** ve **loss** eğrilerini çizmek, son epoch’lara bakarak **overfitting/plato** sinyallerini otomatik yorumlamak.\n\n**Fonksiyonlar**\n- `plot_history(h, title)`:  \n  - Solda: `accuracy` (train vs val)  \n  - Sağda: `loss` (train vs val)\n- `comment_learning_curves(history, tail=5)`:  \n  - Son `k=tail` epoch ortalamalarına göre farkları hesaplar:\n    - `acc_gap = mean(train_acc - val_acc)`  \n      - `> 0.02` → **Overfitting** ihtimali  \n      - `≈ 0` → **Genelleme** iyi  \n    - `loss_gap = mean(val_loss - train_loss)`  \n      - Pozitif ve büyük → **Overfitting** riski\n  - **Plato**: Son `k` epoch’ta `val_acc` artışı `< 0.005` ise uyarır.\n\n**Öneri Şablonları (Duruma Göre)**\n- Overfitting: **Daha güçlü augmentation**, **Dropout/L2↑**, **LR↓**, **EarlyStopping** sıkılaştır.\n- Plato: **ReduceLROnPlateau**, gerekirse **küçük LR ile üst katmanları fine-tune** et.\n- Val > Train: Birkaç epoch daha dene; **LR ısınma/plateau** stratejisini gözden geçir.\n","metadata":{}},{"cell_type":"code","source":"\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n\ndef plot_history(h, title):\n    plt.figure(figsize=(12,4))\n    # Acc\n    plt.subplot(1,2,1)\n    plt.plot(h.history[\"accuracy\"], label=\"train_acc\")\n    plt.plot(h.history[\"val_accuracy\"], label=\"val_acc\")\n    plt.title(f\"{title} - Accuracy\"); plt.grid(True); plt.legend()\n    # Loss\n    plt.subplot(1,2,2)\n    plt.plot(h.history[\"loss\"], label=\"train_loss\")\n    plt.plot(h.history[\"val_loss\"], label=\"val_loss\")\n    plt.title(f\"{title} - Loss\"); plt.grid(True); plt.legend()\n    plt.show()\n\nplot_history(hist1, \"Stage-1\")\n\n\ndef comment_learning_curves(history, tail=5):\n    h = history.history\n    acc  = np.array(h.get(\"accuracy\", []), dtype=float)\n    val_acc = np.array(h.get(\"val_accuracy\", []), dtype=float)\n    loss = np.array(h.get(\"loss\", []), dtype=float)\n    val_loss = np.array(h.get(\"val_loss\", []), dtype=float)\n\n    if len(val_acc)==0 or len(acc)==0:\n        print(\"Not: accuracy/val_accuracy bulunamadı; yorum atlandı.\")\n        return\n\n    # Son k epoch ortalamaları & farklar\n    k = min(tail, len(acc))\n    acc_gap  = float(np.nanmean(acc[-k:] - val_acc[-k:]))   # pozitifse overfit ihtimali\n    loss_gap = float(np.nanmean(val_loss[-k:] - loss[-k:])) if len(val_loss)==len(loss)>0 else np.nan\n\n    # Basit plato göstergesi: son k adımda val_acc artışı çok küçükse\n    plateau = (np.nanmax(val_acc) - np.nanmin(val_acc[-k:])) < 0.005\n\n    lines = []\n    lines.append(f\"Özet: Son {k} epoch ortalamasında accuracy farkı (train - val) ≈ {acc_gap:.3f}.\")\n\n    if acc_gap > 0.02:\n        lines.append(\"Yorum: Train doğruluğu belirgin şekilde daha yüksek → **overfitting** işareti.\")\n        lines.append(\"Öneri: Augmentation’ı güçlendir, Dropout/L2 ekle/artır, LR’ı azalt veya erken durdurmayı sıkılaştır.\")\n    elif acc_gap < -0.01:\n        lines.append(\"Yorum: Val doğruluğu train’den yüksek görünüyor; muhtemelen data shuffle/batch etkisi.\")\n        lines.append(\"Öneri: Birkaç epoch daha eğitip dengele; LR warmup/plateau stratejisini gözden geçir.\")\n    else:\n        lines.append(\"Yorum: Train/Val eğrileri yakın seyrediyor → **genelleme** kabul edilebilir düzeyde.\")\n\n    if plateau:\n        lines.append(\"Not: Val accuracy son dönemde plato yaptı.\")\n        lines.append(\"Öneri: ReduceLROnPlateau/TTA veya alt katmanların bir bölümünü açıp küçük LR ile fine-tuning dene.\")\n\n    if not np.isnan(loss_gap):\n        lines.append(f\"Loss farkı (val - train) ≈ {loss_gap:.3f}. Pozitif ve büyükse overfit riski artar.\")\n\n    print(\"\\n\".join(lines))\n\ncomment_learning_curves(hist1, tail=5)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T21:09:46.973234Z","iopub.execute_input":"2025-09-25T21:09:46.973518Z","iopub.status.idle":"2025-09-25T21:09:47.281599Z","shell.execute_reply.started":"2025-09-25T21:09:46.973497Z","shell.execute_reply":"2025-09-25T21:09:47.280696Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 11) Eğitim Özeti – En İyi Epoch ve Son Değerler\n\nBu hücre, her eğitim aşamasının **en iyi doğrulama başarımını ve son metriklerini kısaca raporlar.**\n\n**Fonksiyon**\n- `summarize_curves(history)`:\n  - `best_val_acc` : En yüksek doğrulama doğruluğu (val_accuracy) ve gerçekleştiği epoch.\n  - `last_train_acc` : Son epoch’taki eğitim doğruluğu.\n  - `last_val_loss` : Son epoch’taki doğrulama kaybı.\n  - Yorum: Eğer **train_acc ≫ val_acc** ise **overfitting** riski vurgulanır. Ayrıca LR düşüşü (ReduceLROnPlateau) sonrası val_loss’un iyileşmesi olumlu olarak not edilir.\n","metadata":{}},{"cell_type":"code","source":"def summarize_curves(history):\n    import numpy as np\n    h = history.history\n    best_val_acc = float(np.max(h.get(\"val_accuracy\", [0.0])))\n    best_val_epoch = int(np.argmax(h.get(\"val_accuracy\", [0.0]))) + 1\n    last_train_acc = float(h.get(\"accuracy\", [0.0])[-1]) if \"accuracy\" in h else float('nan')\n    last_val_loss  = float(h.get(\"val_loss\", [0.0])[-1])  if \"val_loss\"  in h else float('nan')\n    print(\n        f\"[Özet] En iyi val_acc: {best_val_acc:.4f} (epoch {best_val_epoch}) | \"\n        f\"Son train_acc: {last_train_acc:.4f} | Son val_loss: {last_val_loss:.4f}\"\n    )\n\nsummarize_curves(hist1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T21:09:53.757454Z","iopub.execute_input":"2025-09-25T21:09:53.758176Z","iopub.status.idle":"2025-09-25T21:09:53.763866Z","shell.execute_reply.started":"2025-09-25T21:09:53.758115Z","shell.execute_reply":"2025-09-25T21:09:53.763040Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 12) Test Değerlendirme (Tam Sürüm)\n\nBu hücre, **test kümesi performansını** ayrıntılı raporlar ve **confusion matrix** görselleştirir.\n\n**Adımlar**\n- **Gerçek etiketler (`y_true`)**: `test_ds` batch’lerindeki **one-hot** etiketler `argmax` ile sınıf indeksine çevrilerek tek dizide birleştirilir.\n- **Tahminler (`y_pred`)**: `model.predict(test_ds)` çıktısından **en yüksek olasılıklı sınıf** `argmax` ile seçilir (isteğe bağlı: `y_pred_probs` analiz için saklanır).\n- **Sınıflandırma raporu**: `classification_report` → **precision, recall, f1-score** ve support (sınıf başına örnek sayısı).\n- **Confusion matrix**: `confusion_matrix` ile üretilir; sıcaklık haritası olarak çizilir ve hücre içine sayılar yazılır.\n  - `thr = cm.max() / 2` → Metin rengi kontrast için otomatik seçilir (büyük hücrelerde **beyaz**, küçüklerde **siyah**).\n\n**Yorumlama İpuçları**\n- **Diagonal (True=Pred)** hücreler yüksekse model doğru sınıfları iyi yakalıyor demektir.\n- Aynı satırda **yanlış tahmin edilen sütunlar** → o gerçek sınıfın karıştığı sınıfları gösterir (sistematik hata/benzer sınıflar).\n- **Macro vs Weighted F1**: Sınıf dengesizliği varsa `weighted f1` daha temsilî, `macro f1` sınıfları **eşit ağırlıklı** değerlendirir.\n- Düşük kalan sınıflar için: **augmentation çeşitliliği**, **sınıf ağırlıkları** veya **daha fazla veri** değerlendirilebilir.\n\n**Çıktılar**\n- Konsolda ayrıntılı metrik tablosu.\n- Etiket isimleriyle döndürülmüş eksenli, üstünde değer yazan **confusion matrix** grafiği.\n","metadata":{}},{"cell_type":"code","source":"\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport itertools\nimport seaborn as sns\n\n# --- y_true: batch'lerden toplanır ---\ny_true_batches = []\nfor _, y in test_ds:\n    y_true_batches.append(np.argmax(y.numpy(), axis=1))\ny_true = np.concatenate(y_true_batches, axis=0)\n\n# --- y_pred: model tahmini ---\ny_pred_probs = model.predict(test_ds, verbose=0)\ny_pred = np.argmax(y_pred_probs, axis=1)\n\n# --- Rapor ---\nprint(classification_report(y_true, y_pred, target_names=classes, digits=4))\n\n# --- Confusion Matrix ---\ncm = confusion_matrix(y_true, y_pred)\nplt.figure(figsize=(7,6))\nsns.heatmap(cm, annot=True, fmt=\"d\", cbar=False, \n            xticklabels=classes, yticklabels=classes)\nplt.ylabel(\"Gerçek\")\nplt.xlabel(\"Tahmin\")\nplt.title(\"Confusion Matrix\")\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T21:10:00.592654Z","iopub.execute_input":"2025-09-25T21:10:00.592929Z","iopub.status.idle":"2025-09-25T21:10:16.833164Z","shell.execute_reply.started":"2025-09-25T21:10:00.592907Z","shell.execute_reply":"2025-09-25T21:10:16.832407Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 13) Final Test Accuracy (Tek Satır Sonuç)\n\nBu hücre, **test kümesindeki genel doğruluk (accuracy)** değerini tek satırda verir.\n\n- `y_true_vec` ve `y_pred_vec` : Gerçek ve tahmin sınıf indeksleri (tek boyutlu vektörler).  \n- `(y_true_vec == y_pred_vec).mean()` : Doğru tahmin oranını hesaplar.  \n- `print(f\"Test Accuracy: {test_acc:.4f}\")` : Dört ondalık hassasiyetle ekrana yazdırır.\n\n> Bu metrik, projenin **nihai başarı yüzdesini** hızlıca özetler ve raporlarda temel performans göstergesi olarak kullanılabilir.\n","metadata":{}},{"cell_type":"code","source":"import numpy as np\n\ny_true_vec = np.asarray(y_true).squeeze()\ny_pred_vec = np.asarray(y_pred).squeeze()\n\ntest_acc = (y_true_vec == y_pred_vec).mean()\nprint(f\"Test Accuracy: {test_acc:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T21:10:31.931084Z","iopub.execute_input":"2025-09-25T21:10:31.931378Z","iopub.status.idle":"2025-09-25T21:10:31.935939Z","shell.execute_reply.started":"2025-09-25T21:10:31.931357Z","shell.execute_reply":"2025-09-25T21:10:31.935166Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 14) Eigen-CAM ile Görselleştirme\n\nBu hücre, **modelin karar verirken görüntünün hangi bölgelerine odaklandığını** gösterir. Grad-CAM’e benzer, ancak **özdeğer (eigen) ayrışımı** ile en baskın özellikleri yakalar.\n\n**Adımlar**\n- `base = model.get_layer(\"efficientnetb0\")` → EfficientNetB0 taban katmanını alır.\n- `_to_uint8_rgb` → Görüntüyü `[0,255]` aralığında `uint8` formatına çevirir.\n- `eigen_cam_batch` fonksiyonu:\n  1. Özellik haritalarını (`feats`) çıkarır.\n  2. Kovaryans matrisinin en büyük özdeğerine karşılık gelen vektörle **en baskın özellik yönünü** bulur.\n  3. Bu yönü ısı haritasına (heatmap) dönüştürür.\n  4. Orijinal görüntü üzerine yarı saydam olarak bindirir (`alpha=0.35`).\n\n**Kullanım**\n- `for xb, yb in test_ds.take(1)` → Test setinden ilk batch’i alır, ilk 5 görüntüyü işler.\n- Yan yana iki görsel çizilir:\n  - **Input**: Orijinal resim.\n  - **Eigen-CAM**: Modelin en çok dikkate aldığı alanları gösteren ısı haritası.\n\n> Bu yöntem, modelin **hangi piksellerden öğrenme yaptığı** ve **hangi bölgelere odaklandığı** hakkında sezgisel ve görsel bir açıklama sunar. \n","metadata":{}},{"cell_type":"code","source":"\nimport tensorflow as tf, numpy as np, cv2, matplotlib.pyplot as plt\n\ntry:\n    base \nexcept NameError:\n    base = model.get_layer(\"efficientnetb0\") \n\n\ndef _to_uint8_rgb(img_tf):\n    \"\"\"img_tf: tf.Tensor (H,W,3) float/uint8; range [-1,1] veya [0,1] veya [0,255] olabilir.\n       return: np.uint8 [0,255], RGB\n    \"\"\"\n    x = img_tf.numpy()\n    if x.dtype != np.uint8:\n        x = x.astype(np.float32)\n        vmin, vmax = x.min(), x.max()\n       \n        if vmax <= 1.0 and vmin >= -1.0:     \n            if vmin < 0:  # [-1,1]\n                x = (x + 1.0) * 127.5\n            else:         # [0,1]\n                x = x * 255.0\n    \n        x = np.clip(x, 0, 255)\n    return x.astype(np.uint8)  \n\ndef eigen_cam_batch(x_imgs, alpha=0.35):\n    feats = base(x_imgs, training=False)        \n    B, Hc, Wc, C = feats.shape\n    outs = []\n\n    for b in range(B):\n        F   = feats[b]                       \n        F2d = tf.reshape(F, [-1, C])          \n        X   = F2d - tf.reduce_mean(F2d, axis=0, keepdims=True)\n        cov = tf.matmul(X, X, transpose_a=True) / tf.cast(tf.shape(X)[0]-1, tf.float32)\n        _, eigvecs = tf.linalg.eigh(cov)\n        w   = eigvecs[:, -1]                   \n        h   = tf.reshape(tf.matmul(X, w[:, None]), [Hc, Wc])\n        h   = tf.maximum(h, 0)\n        h   = (h - tf.reduce_min(h)) / (tf.reduce_max(h) - tf.reduce_min(h) + 1e-12)\n\n        img = _to_uint8_rgb(x_imgs[b])          \n\n        heat = cv2.resize(h.numpy(), (img.shape[1], img.shape[0]))\n        heat = (255*heat).astype(np.uint8)\n        heat = cv2.applyColorMap(heat, cv2.COLORMAP_JET)          \n        heat = cv2.cvtColor(heat, cv2.COLOR_BGR2RGB)           \n        vis  = cv2.addWeighted(heat, alpha, img, 1-alpha, 0)\n\n        outs.append((img, vis))\n    return outs\n\nfor xb, _ in test_ds.take(1):\n    arr = xb[0].numpy()\n    print(\"dtype:\", arr.dtype, \"min/max:\", arr.min(), arr.max())\n\n# --- ÖRNEK KULLANIM (test setinden 5 görsel) ---\nfor xb, yb in test_ds.take(1):\n    k = min(5, xb.shape[0])\n    res = eigen_cam_batch(xb[:k])\n    for i, (img, vis) in enumerate(res):\n        plt.figure(figsize=(5,3))\n        plt.subplot(1,2,1); plt.imshow(img); plt.axis('off'); plt.title('Input')\n        plt.subplot(1,2,2); plt.imshow(vis); plt.axis('off'); plt.title('Eigen-CAM')\n        plt.tight_layout(); plt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T21:10:35.696170Z","iopub.execute_input":"2025-09-25T21:10:35.696851Z","iopub.status.idle":"2025-09-25T21:10:38.337462Z","shell.execute_reply.started":"2025-09-25T21:10:35.696824Z","shell.execute_reply":"2025-09-25T21:10:38.336784Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 15) Grad-CAM ile Açıklanabilirlik (Base + Head Manuel Zincir)\n\nBu hücre, **base özellik haritası** üzerinden **head’i (sınıflandırıcı kısmı)** elle çağırarak Grad-CAM ısı haritası üretir. Böylece `model.input` sorunlu/None olsa bile çalışır; Eigen-CAM ile aynı batch (`xb`) üzerinde kullanılabilir.\n\n### Ana Fikir\n- **Base (EfficientNetB0)**: Konvolüsyonel özellik haritalarını üretir.\n- **Head (GAP + Dropout + Dense)**: Sınıf olasılıklarını hesaplar. Burada head’i **katman katman** kendimiz uygularız.\n- **Grad-CAM**: Hedef sınıf skorunun, son konvolüsyon çıkışına göre gradyanlarını kullanarak **kanal ağırlıkları** çıkarır ve ısı haritası üretir.\n\n### Bileşenler\n- `_apply_head_from_base_features(feats)`  \n  - `model.layers` içinde `base` katmanından **sonra gelen** katmanları sırayla `feats` üzerine uygular.  \n  - `InputLayer` atlanır; `training=False` verilerek Dropout vb. deterministik çalışır.  \n  - Dönen çıktı: `(1, num_classes)` (veya eşdeğeri).\n- `grad_cam_batch(x_imgs, class_idx=None, alpha=0.35)`  \n  - Her örnek için:  \n    1) `conv_out = base(x1, training=False)`  \n    2) `preds = _apply_head_from_base_features(conv_out)`  \n    3) Hedef skor (`score`):  \n       - `class_idx=None` → **modelin tahmin ettiği sınıf**  \n       - `class_idx=int/list[int]` → **belirlenen sınıf(lar)**  \n    4) `grads = ∂score/∂conv_out` → Kanal başına ortalama al (`weights`)  \n    5) `cam = ReLU(sum(weights * conv_out_channels))` → [0,1] normalize  \n    6) Orijinal resme **ısı haritasını** `alpha` ile yarı saydam bindir.\n  - Dönen çıktı: `(orig_uint8_img, heatmap_overlay_uint8)` listesi.\n\n### Parametreler & İpuçları\n- `class_idx` : Hedef sınıfı kontrol etmek için kullanılır; **yanlış sınıfa bakmayı** önlemek adına faydalıdır.\n- `alpha` : Isı haritası şeffaflığı; 0.25–0.5 arası tipik.\n- Base/Head bağımlılığı: Eğer `grads is None` → head zinciri base çıktısına **bağlı değildir** (mimariyi kontrol edin).\n- Görsel aralığı: `_to_uint8_rgb` her türlü `[−1,1]`, `[0,1]`, `[0,255]` girişini güvenli biçimde `uint8 [0,255]`’e çevirir.","metadata":{}},{"cell_type":"code","source":"def _apply_head_from_base_features(feats, model, base):\n    \"\"\"\n    feats: (1, Hc, Wc, C)  base(x) çıktısı\n    model: tam model (Input -> base -> GAP -> Dropout -> Dense)\n    base : model içindeki conv gövde (ör. model.get_layer('efficientnetb0'))\n    \"\"\"\n    x = feats\n    take = False\n    for ly in model.layers:\n        if ly.name == base.name and not take:\n            take = True\n            continue\n        if not take:\n            continue\n        if isinstance(ly, tf.keras.layers.InputLayer):\n            continue\n        x = ly(x, training=False)\n    return x\n\ndef grad_cam_batch(x_imgs, class_idx=None, alpha=0.35):\n    outs = []\n    B = int(x_imgs.shape[0])\n\n    for b in range(B):\n        x1 = x_imgs[b:b+1]\n\n        with tf.GradientTape() as tape:\n            conv_out = base(x1, training=False)   # (1,Hc,Wc,C)\n            tape.watch(conv_out)\n\n            preds = _apply_head_from_base_features(conv_out, model, base)\n            if preds.shape.rank is None or preds.shape.rank > 2:\n                xgap = tf.reduce_mean(conv_out, axis=[1, 2])\n                drop_ly = None\n                dense_ly = None\n                \n                for ly in reversed(model.layers):\n                    if isinstance(ly, tf.keras.layers.Dense) and dense_ly is None:\n                        dense_ly = ly\n                    elif isinstance(ly, tf.keras.layers.Dropout) and drop_ly is None:\n                        drop_ly = ly\n                    if drop_ly is not None and dense_ly is not None:\n                        break\n                xhead = xgap\n                if drop_ly is not None:\n                    xhead = drop_ly(xhead, training=False)\n                if dense_ly is not None:\n                    preds = dense_ly(xhead, training=False)\n                else:\n                    raise RuntimeError(\"Head katmanları bulunamadı: Dense katmanı sonda bekleniyordu.\")\n\n            # Hedef sınıf\n            if class_idx is None:\n                target_id = tf.argmax(preds[0], axis=-1)   # sınıf ekseni boyunca\n            else:\n                target_id = class_idx if isinstance(class_idx, int) else class_idx[b]\n                target_id = tf.convert_to_tensor(target_id)\n\n            score = preds[0, target_id]\n\n        grads = tape.gradient(score, conv_out)\n        if grads is None:\n            raise RuntimeError(\"Grad alınamadı: head zinciri base çıktısına bağlı değil.\")\n\n        conv  = conv_out[0]                        \n        grad  = grads[0]                           \n        weights = tf.reduce_mean(grad, axis=(0,1), keepdims=True)\n        cam = tf.reduce_sum(weights * conv, axis=-1)  \n        cam = tf.nn.relu(cam).numpy()\n        cam = (cam - cam.min()) / (cam.max() - cam.min() + 1e-12)\n\n        # Görselleştirme\n        img = _to_uint8_rgb(x_imgs[b])\n        heat = cv2.resize(cam.astype(np.float32), (img.shape[1], img.shape[0]))\n        heat = (255 * heat).astype(np.uint8)\n        heat = cv2.applyColorMap(heat, cv2.COLORMAP_JET)\n        heat = cv2.cvtColor(heat, cv2.COLOR_BGR2RGB)\n        vis  = cv2.addWeighted(heat, alpha, img, 1 - alpha, 0)\n        outs.append((img, vis))\n    return outs\n    \nfor xb, yb in test_ds.take(1):\n    k = min(5, xb.shape[0])\n    res_eigen = eigen_cam_batch(xb[:k], alpha=0.35)   # mevcut çalışan\n    res_grad  = grad_cam_batch (xb[:k], alpha=0.35)   # yeni\n\n    for i in range(k):\n        img_e, vis_e = res_eigen[i]\n        img_g, vis_g = res_grad[i]\n        plt.figure(figsize=(9,3))\n        plt.subplot(1,3,1); plt.imshow(img_e); plt.axis('off'); plt.title('Input')\n        plt.subplot(1,3,2); plt.imshow(vis_e); plt.axis('off'); plt.title('Eigen-CAM')\n        plt.subplot(1,3,3); plt.imshow(vis_g); plt.axis('off'); plt.title('Grad-CAM')\n        plt.tight_layout(); plt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T21:10:46.570941Z","iopub.execute_input":"2025-09-25T21:10:46.571476Z","iopub.status.idle":"2025-09-25T21:10:52.169837Z","shell.execute_reply.started":"2025-09-25T21:10:46.571453Z","shell.execute_reply":"2025-09-25T21:10:52.169092Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 16) CAM Görsellerinden Seçki (2 Doğru + 2 Yanlış)\n\nBu hücre, test kümesinden **doğru sınıflandırılmış** ve **yanlış sınıflandırılmış** örneklerden seçerek **Eigen-CAM / Grad-CAM** bindirmelerini yan yana gösterir.\n\n**Fonksiyon**\n- `show_cam_samples_from_ds(test_ds, y_true_vec, y_pred_vec, classes, eigen_cam_fn, grad_cam_fn, alpha=0.35, k_correct=2, k_wrong=2)`\n  - **Toplama**: `test_ds` içindeki tüm görüntüler belleğe alınır (`x_all`).  \n  - **Seçim**:  \n    - `correct_idx`: `y_true_vec == y_pred_vec` (doğru tahminler)  \n    - `wrong_idx`  : `y_true_vec != y_pred_vec` (yanlış tahminler)  \n    - İlk `k_correct` ve `k_wrong` örnek alınır.  \n  - **CAM üretimi**:  \n    - `eigen_cam_fn(xb_tf, alpha)` → `(img, vis)`  \n    - `grad_cam_fn(xb_tf, alpha)`  → `(img, vis)`  \n    - Her örnek için Input + (varsa) Eigen-CAM + Grad-CAM sütunları çizilir.\n  - **Başlıklar**: `T:{true_c} / P:{pred_c}` ile gerçek/tahmin edilen sınıflar gösterilir.\n\n**Önemli Notlar**\n- Fonksiyon, CAM için `tf.float32` tensörüne dönüştürür (**`xb_tf`**).  \n- Görüntü çiziminde `plt.imshow(np.uint8(xb[0]))` kullanılıyor.  \n  - Eğer pipeline’da görüntüler **[-1, 1]** aralığındaysa, orijinal input’u doğru görmek için **önce** `[0,255]` aralığına ölçeklemek gerekebilir (aksi halde soluk/bozuk görünebilir).  \n  - CAM bindirmeleri (`vis`) zaten `uint8` ve doğru aralıktadır (Eigen-CAM/Grad-CAM içinde `_to_uint8_rgb` kullanılıyor).\n","metadata":{}},{"cell_type":"code","source":"\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nimport tensorflow as tf\n\ndef show_cam_samples_from_ds(test_ds, y_true_vec, y_pred_vec, classes,\n                             eigen_cam_fn=None, grad_cam_fn=None,\n                             alpha=0.35, k_correct=2, k_wrong=2):\n    \"\"\"\n    test_ds     : tf.data.Dataset -> (images, labels)  [labels one-hot olabilir]\n    y_true_vec  : 1D numpy array, gerçek sınıf indeksleri\n    y_pred_vec  : 1D numpy array, tahmin sınıf indeksleri\n    classes     : sınıf isim listesi\n    \"\"\"\n   \n    x_batches = []\n    for x, _ in test_ds:\n        x_batches.append(x.numpy())\n    x_all = np.concatenate(x_batches, axis=0)\n\n    correct_idx = np.where(y_true_vec == y_pred_vec)[0]\n    wrong_idx   = np.where(y_true_vec != y_pred_vec)[0]\n\n    pick_correct = correct_idx[:k_correct]\n    pick_wrong   = wrong_idx[:k_wrong]\n    chosen = list(pick_correct) + list(pick_wrong)\n\n    for i in chosen:\n        xb = x_all[i:i+1]\n        row_imgs = []\n\n        if eigen_cam_fn is not None:\n            xb_tf = tf.convert_to_tensor(xb, dtype=tf.float32)  \n            img_e, vis_e = eigen_cam_fn(xb_tf, alpha=alpha)[0]\n            row_imgs.append((\"Eigen-CAM\", vis_e))\n        \n        if grad_cam_fn is not None:\n            xb_tf = tf.convert_to_tensor(xb, dtype=tf.float32)  \n            img_g, vis_g = grad_cam_fn(xb_tf, alpha=alpha)[0]\n            row_imgs.append((\"Grad-CAM\", vis_g))\n\n        cols = len(row_imgs) + 1\n        plt.figure(figsize=(4*cols, 4))\n        # Orijinal görüntü\n        plt.subplot(1, cols, 1)\n        plt.imshow(np.uint8(xb[0]))\n        plt.axis('off')\n        true_c = classes[int(y_true_vec[i])]\n        pred_c = classes[int(y_pred_vec[i])]\n        plt.title(f\"Input\\nT:{true_c} / P:{pred_c}\")\n\n        for j, (name, overlay) in enumerate(row_imgs, start=2):\n            plt.subplot(1, cols, j)\n            plt.imshow(overlay)\n            plt.axis('off')\n            plt.title(name)\n\n        plt.tight_layout()\n        plt.show()\n\nshow_cam_samples_from_ds(\n    test_ds,\n    y_true_vec,\n    y_pred_vec,\n    classes,\n    eigen_cam_fn=eigen_cam_batch,\n    grad_cam_fn=grad_cam_batch,\n    alpha=0.35\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T21:10:57.530297Z","iopub.execute_input":"2025-09-25T21:10:57.530859Z","iopub.status.idle":"2025-09-25T21:11:03.276727Z","shell.execute_reply.started":"2025-09-25T21:10:57.530837Z","shell.execute_reply":"2025-09-25T21:11:03.276041Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 17) Tek Görselden Tahmin (predict_file)\n\nBu fonksiyon, **kaydedilmiş modeli kullanarak tek bir resim için sınıf tahmini yapar**.\n\n**Adımlar**\n- `Image.open(img_path).convert(\"RGB\").resize((IMG_SIZE, IMG_SIZE))`  \n  → Resmi RGB formatına çevirip modelin beklediği boyuta getirir.\n- `np.array(img).astype(\"float32\")`  \n  → Görüntüyü sayısal tensöre dönüştürür.\n- `preprocess_input(x)`  \n  → Piksel değerlerini **[-1,1]** aralığına normalize eder.\n- `model.predict(x[None, ...])`  \n  → Tek resmi batch boyutuna genişleterek tahmin eder.\n- `argsort()[::-1][:topk]`  \n  → En yüksek olasılıklı **ilk `topk` sınıfı** seçer (varsayılan `topk=3`).\n","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.applications.efficientnet import preprocess_input\nfrom PIL import Image\nimport numpy as np, tensorflow as tf\n\ndef predict_file(img_path, topk=3):\n    img = Image.open(img_path).convert(\"RGB\").resize((IMG_SIZE, IMG_SIZE))\n    x   = np.array(img).astype(\"float32\")\n    x   = preprocess_input(x)                      # [-1,1]\n    pr  = model.predict(x[None, ...], verbose=0)[0]\n    idx = pr.argsort()[::-1][:topk]\n    return [(classes[i], float(pr[i])) for i in idx]\n\npreds = predict_file(\"/kaggle/input/flowers-recognition/flowers/rose/10090824183_d02c613f10_m.jpg\")\nfor cls, prob in preds:\n    print(f\"{cls}: {prob:.2%}\")\n   \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T21:11:10.021574Z","iopub.execute_input":"2025-09-25T21:11:10.021818Z","iopub.status.idle":"2025-09-25T21:11:17.295247Z","shell.execute_reply.started":"2025-09-25T21:11:10.021801Z","shell.execute_reply":"2025-09-25T21:11:17.294565Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 18) Test-Time Augmentation (TTA) ile Tahmin\n\nBu adım, **tahmin sırasında veri artırma** (örn. yatay çevirme) uygulayarak modelin genelleme gücünü artırır ve **daha kararlı sonuçlar** elde eder.\n\n### Fonksiyon\n- `predict_with_tta(x_batch, n=4)`\n  - `x_batch` : Önceden `preprocess_input` uygulanmış görüntü batch’i.\n  - `n` : Aynı batch için kaç farklı görünüm (augmentation) ile tahmin alınacağı.\n  - Döngü:\n    - Çift turlar → orijinal görüntü  \n    - Tek turlar → **yatay çevrilmiş** görüntü (`tf.image.flip_left_right`).\n    - `model.predict` çıktıları `outs` listesine eklenir.\n  - `np.mean(outs, axis=0)` → Tüm tahminlerin ortalaması alınır (**olasılıkları yumuşatır**).","metadata":{}},{"cell_type":"code","source":"def predict_with_tta(x_batch, n=4):  \n    outs = []\n    for t in range(n):\n        xb = x_batch\n        if t % 2 == 1:\n            xb = tf.image.flip_left_right(xb)\n        pr = model.predict(xb, verbose=0)\n        outs.append(pr)\n    return np.mean(outs, axis=0)\n\n\navg_probs = np.vstack([predict_with_tta(xb) for xb, _ in test_ds])\ny_pred = avg_probs.argmax(1)\ntta_acc = (y_true_vec == y_pred).mean()\n\n\nidx = 0   # test setindeki ilk örnek\nprint(\"Gerçek sınıf:\", classes[y_true_vec[idx]])\nprint(\"Tahmin edilen:\", classes[y_pred[idx]])\nprint(\"Ortalama olasılıklar:\", avg_probs[idx])\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T21:11:22.295643Z","iopub.execute_input":"2025-09-25T21:11:22.295905Z","iopub.status.idle":"2025-09-25T21:11:41.563547Z","shell.execute_reply.started":"2025-09-25T21:11:22.295887Z","shell.execute_reply":"2025-09-25T21:11:41.562863Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 19) Bottleneck (Önceden Çıkarılmış Özellik) Yaklaşımı – Hızlı Arama\n\nBu blok, EfficientNetB0’un konvolüsyonel kısmını **donuk (frozen) özellik çıkarıcı** olarak kullanıp, eğitim verisini **bir kez ileri geçirerek** (forward) **bottleneck** özelliklerini RAM’e (veya dosyaya) alır. Amaç: **deneme/arama hızını** büyük ölçüde artırmak.\n\n**Ne yapar?**\n- `IMG_SIZE` hem `int` hem `(H,W)` gelirse uyumludur.\n- `feature_extractor`: `EfficientNetB0(include_top=False)` + `GlobalAveragePooling2D`  \n  → Sadece **özellik** üretir, **eğitilmez** (`trainable=False`).\n- `subset_frac`: Hızlı denemeler için eğitim/validasyonun bir **alt kısmını** kullanır (örn. 0.3).\n- `ds_to_features(ds)`:  \n  - Her batch’i `feature_extractor` içinden geçirip `(B, C)` boyutlu özellikleri toplar.  \n  - Etiketleri de toplar; **one-hot** ise **sparse** sınıf indeksine çevirir.  \n- `np.savez(...)`: Özellikleri ve etiketleri diske kaydeder (isteğe bağlı).\n\n**Çıktılar**\n- `Xtr, ytr`: Eğitim özellikleri ve etiketler  \n- `Xva, yva`: Validasyon özellikleri ve etiketler  \n- Örnek: `Train feats: (N_train, C)  Val feats: (N_val, C)`\n\n**Neden faydalı?**\n- Üstte küçük bir **head** (Dense + Dropout vb.) eğiterek **çok hızlı** model araması (LR, dropout, hidden size...) yapabilirsiniz.\n- Ağır konvolüsyon kısmı her seferinde çalışmadığından **GPU/CPU süresi** kısalır.\n\n\n> Özet: Bottleneck yaklaşımı, **hızlı prototipleme ve hiperparametre araması** için idealdir; sonrasında dilerseniz tam eğitim (end-to-end veya kademeli fine-tuning) ile sonuçları rafine edebilirsiniz.\n","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf, numpy as np, os, pandas as pd\nfrom tensorflow.keras import layers, models\n\n\nif isinstance(IMG_SIZE, tuple):\n    H, W = IMG_SIZE\nelse:\n    H = W = int(IMG_SIZE)\n\nnum_classes = len(classes)\ninp = tf.keras.Input(shape=(H, W, 3))\nb0  = tf.keras.applications.EfficientNetB0(include_top=False, weights=\"imagenet\")(inp, training=False)\ngap = layers.GlobalAveragePooling2D()(b0)\nfeature_extractor = models.Model(inp, gap, name=\"b0_gap\")\nfeature_extractor.trainable = False\n\nsubset_frac = 1.0  \ndef take_fraction(ds, frac):\n    if frac >= 1.0: return ds\n    total = 0\n    for _ in ds: total += 1\n    take_n = max(1, int(total*frac))\n    return ds.take(take_n)\n\ntrain_search = take_fraction(train_ds, subset_frac)\nval_search   = take_fraction(val_ds,   subset_frac)\n\ndef ds_to_features(ds):\n    X, y = [], []\n    for xb, yb in ds:\n        feats = feature_extractor(xb, training=False).numpy()  # (B, C)\n        X.append(feats)\n        y.append(yb.numpy())\n    X = np.concatenate(X, axis=0)\n    y = np.concatenate(y, axis=0)\n\n    if y.ndim == 2 and y.shape[1] == num_classes:\n        y = y.argmax(axis=1)\n    return X, y.astype(\"int32\")\n\nXtr, ytr = ds_to_features(train_search)\nXva, yva = ds_to_features(val_search)\n\nprint(\"Train feats:\", Xtr.shape, \"Val feats:\", Xva.shape)\nnp.savez(\"/kaggle/working/bottlenecks.npz\", Xtr=Xtr, ytr=ytr, Xva=Xva, yva=yva)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T21:11:47.234758Z","iopub.execute_input":"2025-09-25T21:11:47.235546Z","iopub.status.idle":"2025-09-25T21:12:22.846779Z","shell.execute_reply.started":"2025-09-25T21:11:47.235520Z","shell.execute_reply":"2025-09-25T21:12:22.846103Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 20) Hızlı Hiperparametre Araması (Optimizer + Batch Size Dahil)\n\nBu hücre, **bottleneck özellikleri** üzerinde yalnızca **üst sınıflandırıcı (head)** için  \nhızlı ve geniş kapsamlı bir **hiperparametre araması** yapar.  \nÖnceki bloklarda oluşturulan `Xtr, ytr, Xva, yva` verilerini kullanır.\n\n### Adımlar\n\n1. **Bottleneck Özellik Çıkarımı (subset_frac=0.5)**  \n   - Eğitim ve doğrulama verilerinin %50’si alınır.  \n   - EfficientNetB0 gövdesi **donuk** bırakılır.  \n   - Böylece veri boyutu yarıya iner ve deneyler çok daha hızlı tamamlanır.\n\n2. **Head Modeli Kurulumu ve Eğitimi**  \n   - Mimari: `Dense(dense_units, relu)` (opsiyonel) → `Dropout(drop)` → `Dense(num_classes, softmax)`.\n   - Kayıp fonksiyonu: `SparseCategoricalCrossentropy`.  \n   - Metrik: `accuracy`.\n   - Erken durdurma (`EarlyStopping`) ile aşırı eğitim engellenir.\n\n3. **Grid Araması**  \n   - Öğrenme oranı (`lr`): **1e-3**, **5e-4**  \n   - Dropout (`drop`): **0.3**, **0.5**  \n   - Gizli katman nöron sayısı (`dense_units`): **0**, **128**  \n   - Optimizasyon algoritması (`optimizer`): **adam**, **rmsprop**  \n   - Batch size (`batch_size`): **32**, **64**  \n   - Toplam **24 kombinasyon** denenir. \n\n4. **Raporlama ve Kayıt**  \n   - Tüm denemeler `df` DataFrame’inde saklanır, **val_acc**’e göre sıralanır.\n   - Sonuçlar `/kaggle/working/results_hparam_search.csv` dosyasına kaydedilir.\n   - En iyi kombinasyon ve en yüksek `val_acc` konsola yazdırılır.\n","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf, numpy as np, pandas as pd\nfrom tensorflow.keras import layers, models, optimizers, losses, callbacks\n\n\nif isinstance(IMG_SIZE, tuple):\n    H, W = IMG_SIZE\nelse:\n    H = W = int(IMG_SIZE)\n\nnum_classes = len(classes)\ninp = tf.keras.Input(shape=(H, W, 3))\nb0  = tf.keras.applications.EfficientNetB0(include_top=False, weights=\"imagenet\")(inp, training=False)\ngap = layers.GlobalAveragePooling2D()(b0)\nfeature_extractor = models.Model(inp, gap, name=\"b0_gap\")\nfeature_extractor.trainable = False\n\n\nsubset_frac = 0.5\ndef take_fraction(ds, frac: float):\n    if frac >= 1.0:\n        return ds\n    total = 0\n    for _ in ds:\n        total += 1\n    take_n = max(1, int(total * frac))\n    return ds.take(take_n)\n\ntrain_search = take_fraction(train_ds, subset_frac)\nval_search   = take_fraction(val_ds,   subset_frac)\n\ndef ds_to_features(ds):\n    X, y = [], []\n    for xb, yb in ds:\n        feats = feature_extractor(xb, training=False).numpy() \n        X.append(feats)\n        y.append(yb.numpy())\n    X = np.concatenate(X, axis=0)\n    y = np.concatenate(y, axis=0)\n    if y.ndim == 2 and y.shape[1] == num_classes: \n        y = y.argmax(axis=1)\n    return X, y.astype(\"int32\")\n\nXtr, ytr = ds_to_features(train_search)\nXva, yva = ds_to_features(val_search)\nprint(f\"[Hızlı Mod] Train feats: {Xtr.shape}, Val feats: {Xva.shape} (subset_frac={subset_frac})\")\nearly_stop = callbacks.EarlyStopping(monitor=\"val_accuracy\", patience=2, restore_best_weights=True)\n\ndef make_optimizer(name: str, lr: float):\n    name = (name or \"adam\").lower()\n    if name == \"adam\":\n        return optimizers.Adam(learning_rate=lr)\n    if name == \"rmsprop\":\n        return optimizers.RMSprop(learning_rate=lr)\n    if name == \"sgd\":\n        return optimizers.SGD(learning_rate=lr, momentum=0.9, nesterov=True)\n    raise ValueError(f\"Bilinmeyen optimizer: {name}\")\n\ndef quick_try_head(\n    lr=1e-3,\n    drop=0.4,\n    dense_units=0,\n    optimizer_name=\"adam\",\n    batch_size=64,\n    epochs=8,        \n    verbose=0,\n):\n    inputs = layers.Input(shape=(Xtr.shape[1],))\n    x = inputs\n    if dense_units > 0:\n        x = layers.Dense(dense_units, activation=\"relu\")(x)\n        x = layers.Dropout(drop)(x)\n    else:\n        x = layers.Dropout(drop)(x)\n    outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n\n    m = models.Model(inputs, outputs)\n    m.compile(optimizer=make_optimizer(optimizer_name, lr),\n              loss=losses.SparseCategoricalCrossentropy(),\n              metrics=[\"accuracy\"])\n\n    h = m.fit(\n        Xtr, ytr,\n        validation_data=(Xva, yva),\n        epochs=epochs,\n        batch_size=batch_size,\n        callbacks=[early_stop],\n        verbose=verbose,\n    )\n    return float(max(h.history[\"val_accuracy\"])), m\n\n\ngrid_lr   = [1e-3, 5e-4]\ngrid_drop = [0.3, 0.5]\ngrid_dense= [0, 128]\ngrid_opt  = [\"adam\", \"rmsprop\"]      \ngrid_bs   = [32, 64]\n\ntries = []\nbest_cfg, best_acc, best_model = None, -1.0, None\n\nfor lr in grid_lr:\n    for drop in grid_drop:\n        for dense in grid_dense:\n            for opt_name in grid_opt:\n                for bs in grid_bs:\n                    acc, model_head = quick_try_head(\n                        lr=lr,\n                        drop=drop,\n                        dense_units=dense,\n                        optimizer_name=opt_name,\n                        batch_size=bs,\n                        epochs=8,   \n                        verbose=0,\n                    )\n                    tries.append((lr, drop, dense, opt_name, bs, acc))\n                    if acc > best_acc:\n                        best_cfg, best_acc, best_model = (lr, drop, dense, opt_name, bs), acc, model_head\n\ncols = [\"lr\", \"dropout\", \"dense_units\", \"optimizer\", \"batch_size\", \"val_acc\"]\ndf = pd.DataFrame(tries, columns=cols).sort_values(\"val_acc\", ascending=False)\ndf.to_csv(\"/kaggle/working/results_hparam_search.csv\", index=False)\nprint(\"Tablo kaydedildi\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T21:14:55.305533Z","iopub.execute_input":"2025-09-25T21:14:55.305775Z","iopub.status.idle":"2025-09-25T21:17:02.036381Z","shell.execute_reply.started":"2025-09-25T21:14:55.305760Z","shell.execute_reply":"2025-09-25T21:17:02.035645Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 21) Hiperparametre Arama Sonuçlarının Tabloya Dökülmesi\n\nBu hücre, `tries` listesindeki tüm denemeleri **DataFrame**’e çevirir, en iyi doğrulamaya göre sıralar ve hem **CSV** hem **Markdown** biçiminde çıktılar.\n\n**Adımlar**\n- `tries` içeriğine göre sütun adlarını otomatik belirler:  \n  - 3 elemanlı tuple → `[\"learning_rate\", \"dropout\", \"val_acc\"]`  \n  - 6 elemanlı tuple → `[\"lr\", \"dropout\", \"dense_units\", \"optimizer\", \"batch_size\", \"val_acc\"]`\n- `df.sort_values(\"val_acc\", ascending=False)` → En yüksek doğruluk üste alınır.\n- `df.to_csv(\"/kaggle/working/results_hparam_search.csv\")` → Sonuçlar **CSV** dosyası olarak kaydedilir.\n- `df.to_markdown()` → Notebook çıktısında **Markdown tablosu** halinde gösterir.  \n  - `tabulate` yüklü değilse fallback olarak `tabulate()` ile basit biçimde basar.\n","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\nif not tries:\n    raise ValueError(\"tries boş görünüyor.\")\n\nn = len(tries[0])\nif n == 3:\n    cols = [\"learning_rate\", \"dropout\", \"val_acc\"]\nelif n == 6:\n    cols = [\"lr\", \"dropout\", \"dense_units\", \"optimizer\", \"batch_size\", \"val_acc\"]\nelse:\n    cols = [f\"col{i}\" for i in range(n)]  \ndf = pd.DataFrame(tries, columns=cols)\ndf = df.sort_values(\"val_acc\", ascending=False)\ndf.to_csv(\"/kaggle/working/results_hparam_search.csv\", index=False)\n\ntry:\n    print(df.to_markdown(index=False))\nexcept Exception:\n    from tabulate import tabulate \n    print(tabulate(df, headers='keys', tablefmt='github', showindex=False))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T21:18:58.974341Z","iopub.execute_input":"2025-09-25T21:18:58.975007Z","iopub.status.idle":"2025-09-25T21:18:59.015329Z","shell.execute_reply.started":"2025-09-25T21:18:58.974982Z","shell.execute_reply":"2025-09-25T21:18:59.014701Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 22) En İyi Hiperparametre Seti ve Kısa Gerekçe\n\nBu hücre, hiperparametre aramasında elde edilen en iyi kombinasyonu ve kısa bir seçim gerekçesini otomatik olarak raporlar.\n\n**Adımlar**\n- `best_idx = df[\"val_acc\"].idxmax()` → En yüksek doğrulama doğruluğuna sahip satırın indeksini bulur.\n- `best = df.loc[best_idx].to_dict()` → Bu satırdaki tüm hiperparametreleri (ör. lr, dropout, dense_units…) sözlük olarak alır.\n- `print` döngüsü ile her hiperparametre ve değeri satır satır gösterir.\n\n**Gerekçe Mantığı**\n- En yüksek `val_acc` değeri temel alınır.\n- İlk 3 sonucu inceler; eğer 1. ve 2. skorlar **çok yakınsa (<0.005 fark)**:\n  - Dropout veya L2 gibi **düzenlileştirme** parametreleri karşılaştırılır.\n  - Daha yüksek düzenlileştirme varsa **daha stabil ve genelleştirilebilir** yapı vurgulanır.\n- Fark belirgin ise: “Alternatiflere göre belirgin şekilde daha yüksek doğrulama başarımı” notu eklenir.\n","metadata":{}},{"cell_type":"code","source":"\nimport numpy as np\n\nassert \"val_acc\" in df.columns, \"df içinde 'val_acc' sütunu yok!\"\nbest_idx = df[\"val_acc\"].idxmax()\nbest = df.loc[best_idx].to_dict()\n\nprint(\"Seçilen en iyi set:\")\nfor k, v in best.items():\n    print(f\" - {k}: {v}\")\n\ntop3 = df.sort_values(\"val_acc\", ascending=False).head(3).reset_index(drop=True)\nmsg = [f\"\\nGerekçe:\",\n       f\"- En yüksek doğrulama başarımı: {top3.loc[0,'val_acc']:.4f}.\"]\n\nif len(top3) > 1 and (top3.loc[0,\"val_acc\"] - top3.loc[1,\"val_acc\"]) < 0.005:\n    hint_cols = [c for c in df.columns if (\"dropout\" in c.lower()) or (\"l2\" in c.lower())]\n    if hint_cols:\n        better_reg = []\n        for c in hint_cols:\n            v0 = top3.loc[0, c]\n            v1 = top3.loc[1, c]\n            if isinstance(v0, (int,float)) and isinstance(v1, (int,float)) and v0>=v1:\n                better_reg.append(f\"{c}={v0}\")\n        if better_reg:\n            msg.append(f\"- Yakın rakibe kıyasla daha güçlü düzenlileştirme ({', '.join(better_reg)}) içeriyor.\")\n    msg.append(\"- Skorlar çok yakın olduğu için daha **stabil** ve **genelleştirilebilir** yapı tercih edildi.\")\nelse:\n    msg.append(\"- Alternatiflere göre belirgin şekilde daha yüksek doğrulama başarımı.\")\n\nprint(\"\\n\".join(msg))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T21:19:04.267575Z","iopub.execute_input":"2025-09-25T21:19:04.268288Z","iopub.status.idle":"2025-09-25T21:19:04.277874Z","shell.execute_reply.started":"2025-09-25T21:19:04.268263Z","shell.execute_reply":"2025-09-25T21:19:04.277164Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 23) Yanlış Sınıflandırılan Örnekleri Görselleştirme\n\nBu hücre, **test kümesinde modelin yanıldığı ilk 15 örneği** doğru/güvenli bir görüntü ölçeklemesiyle çizip kaydeder.\n\n**Ne yapıyor?**\n- `to_uint8_rgb(x)`  \n  - Görüntüyü olası aralıklardan (`[-1,1]`, `[0,1]`, `[0,255]`) **güvenle** `uint8 [0,255]` aralığına çevirir.  \n  - CAM görselleriyle tutarlı ve “doğal renkli” görüntü sunar.\n- `y_true` / `y_pred`  \n  - Test kümesinden **gerçek etiketleri** (one-hot’tan `argmax`) ve **tahminleri** üretir.  \n  - `mis_idx` ile **yanlış tahmin edilen** indeksler bulunur.\n- Görsellerin derlenmesi  \n  - `test_ds` içindeki tüm batch’lerdeki görüntüler `to_uint8_rgb` ile normalize edilip `test_images` listesine eklenir.\n- Çizim ve kayıt  \n  - `matplotlib` ile 3×5 düzeninde **ilk 15 yanlış örnek** çizilir.  \n  - Başlık: `T:{gerçek sınıf} / P:{tahmin edilen sınıf}`  \n  - Dosya kaydı: `/kaggle/working/misclassified_examples.png`\n\n**Neden önemli?**\n- Modelin **hangi sınıflarda ve hangi tür görsellerde yanıldığı** hızla görülür.  \n- Karışan sınıfları inceleyip **augmentation** stratejisi, sınıf ağırlıkları veya veri kalitesi hakkında iyileştirme kararları alabilirsiniz.\n","metadata":{}},{"cell_type":"code","source":"import numpy as np, matplotlib.pyplot as plt\n\ndef to_uint8_rgb(x):\n    \"\"\"\n    x: np.ndarray or tf.Tensor, shape (H,W,3)\n       Olası aralıklar: [-1,1] ya da [0,1] ya da [0,255]\n    return: np.uint8 in [0,255]\n    \"\"\"\n    if hasattr(x, \"numpy\"):\n        x = x.numpy()\n    x = x.astype(np.float32)\n    vmin, vmax = x.min(), x.max()\n    if vmax <= 1.0 and vmin >= -1.0:   # [-1,1] veya [0,1]\n        if vmin < 0:                   # [-1,1]\n            x = (x + 1.0) * 127.5\n        else:                          # [0,1]\n            x = x * 255.0\n    x = np.clip(x, 0, 255).astype(np.uint8)\n    return x\n\ny_true_batches = []\nfor _, y in test_ds:\n    y_true_batches.append(np.argmax(y.numpy(), axis=1))\ny_true = np.concatenate(y_true_batches, axis=0)\ny_pred_probs = model.predict(test_ds, verbose=0)\ny_pred = np.argmax(y_pred_probs, axis=1)\nmis_idx = np.where(y_true != y_pred)[0]\ntest_images = []\nfor xb, _ in test_ds:\n    imgs = np.stack([to_uint8_rgb(im) for im in xb]) \n    test_images.extend(imgs)\n\nfig, axes = plt.subplots(3, 5, figsize=(12, 7))\nfor ax, i in zip(axes.ravel(), mis_idx[:15]):\n    ax.imshow(test_images[i])\n    ax.set_title(f\"T:{classes[y_true[i]]}\\nP:{classes[y_pred[i]]}\")\n    ax.axis('off')\nplt.tight_layout()\nplt.savefig(\"/kaggle/working/misclassified_examples.png\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T21:19:10.391959Z","iopub.execute_input":"2025-09-25T21:19:10.392235Z","iopub.status.idle":"2025-09-25T21:19:14.336535Z","shell.execute_reply.started":"2025-09-25T21:19:10.392217Z","shell.execute_reply":"2025-09-25T21:19:14.335584Z"}},"outputs":[],"execution_count":null}]}