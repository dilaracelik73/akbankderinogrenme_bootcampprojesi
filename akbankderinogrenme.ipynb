{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":2431805,"sourceType":"datasetVersion","datasetId":8782}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## 1) Ortam Kurulumu ve Tekrarlanabilirlik\n\nBu hÃ¼cre, derin Ã¶ÄŸrenme projelerine baÅŸlamadan Ã¶nce **Ã§alÄ±ÅŸma ortamÄ±nÄ± hazÄ±rlar ve sonuÃ§larÄ±n tekrarlanabilir olmasÄ±nÄ± saÄŸlar.**\n\n- **KÃ¼tÃ¼phaneler**: `os`, `random`, `numpy`, `tensorflow` modÃ¼lleri iÃ§e aktarÄ±lÄ±r.  \n- **Log dÃ¼zeni**: `os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"` ile TensorFlowâ€™un gereksiz uyarÄ± ve bilgi mesajlarÄ± gizlenir.  \n- **Rastgelelik sabitleme**: `random.seed`, `np.random.seed` ve `tf.random.set_seed` komutlarÄ± ile tÃ¼m rastgele iÅŸlemler aynÄ± baÅŸlangÄ±Ã§ deÄŸerine baÄŸlanÄ±r. Bu sayede her Ã§alÄ±ÅŸtÄ±rmada aynÄ± sonuÃ§lar alÄ±nabilir (**reproducibility**).  \n- **GPU bellek yÃ¶netimi**: `tf.config.experimental.set_memory_growth` ile TensorFlow GPU belleÄŸini ihtiyaÃ§ oldukÃ§a kullanÄ±r, ilk baÅŸta tamamÄ±nÄ± rezerve etmez. Bu, bellek taÅŸma (OOM) hatalarÄ±nÄ± Ã¶nlemeye yardÄ±mcÄ± olur.  \n- **Durum bildirimi**: Mevcut fiziksel GPU sayÄ±sÄ± ekrana yazdÄ±rÄ±lÄ±r; `0` gÃ¶rÃ¼lÃ¼rse iÅŸlem CPU Ã¼zerinden yapÄ±lÄ±r.\n\n> Bu hÃ¼cre sayesinde **temiz, dÃ¼zenli ve Ã¶ngÃ¶rÃ¼lebilir bir Ã§alÄ±ÅŸma ortamÄ±** oluÅŸturulur.\n","metadata":{}},{"cell_type":"code","source":"import os, random, numpy as np, tensorflow as tf\n\nos.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\nSEED = 42\nrandom.seed(SEED); np.random.seed(SEED); tf.random.set_seed(SEED)\ngpus = tf.config.list_physical_devices('GPU')\nfor g in gpus:\n    try: tf.config.experimental.set_memory_growth(g, True)\n    except: pass\nprint(\"GPU sayÄ±sÄ±:\", len(gpus))\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-25T21:02:48.840977Z","iopub.execute_input":"2025-09-25T21:02:48.841636Z","iopub.status.idle":"2025-09-25T21:03:09.007141Z","shell.execute_reply.started":"2025-09-25T21:02:48.841612Z","shell.execute_reply":"2025-09-25T21:03:09.006304Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 2) Veri YollarÄ±nÄ±n Belirlenmesi ve KeÅŸif (Data Paths & Exploration)\n\nBu hÃ¼crede **gÃ¶rÃ¼ntÃ¼ verisinin yolu belirlenir, dosyalar listelenir ve eÄŸitim/validasyon/test ayrÄ±mÄ± yapÄ±lÄ±r.**\n\n- **KÃ¼tÃ¼phaneler**:  \n  - `pandas`: Veri Ã§erÃ§evesi (DataFrame) oluÅŸturma ve dÃ¼zenleme iÃ§in.  \n  - `pathlib.Path`: Dosya yollarÄ±nÄ± platformdan baÄŸÄ±msÄ±z biÃ§imde yÃ¶netmek iÃ§in.  \n\n- **Veri konumu**: `DATA_DIR` ile Kaggleâ€™Ä±n *flowers-recognition* veri kÃ¼mesindeki kÃ¶k klasÃ¶r tanÄ±mlanÄ±r. Alt klasÃ¶rler Ã§iÃ§ek sÄ±nÄ±flarÄ±nÄ± (Ã¶rneÄŸin *rose*, *daisy*) temsil eder.\n\n- **Dosya listesi Ã§Ä±karma**:  \n  - `glob` yÃ¶ntemi ile `*.jpg`, `*.jpeg`, `*.png` uzantÄ±lÄ± tÃ¼m gÃ¶rÃ¼ntÃ¼ler bulunur.  \n  - Her bir dosyanÄ±n tam yolu `paths`, dosyanÄ±n klasÃ¶r adÄ± ise (etiket) `labels` listesine kaydedilir.\n\n- **Veri Ã§erÃ§evesi**: `df` adlÄ± DataFrameâ€™de her satÄ±rda bir gÃ¶rÃ¼ntÃ¼ yolu ve buna karÅŸÄ±lÄ±k gelen etiket bulunur.  \n  - `sample(frac=1, random_state=SEED)` verileri karÄ±ÅŸtÄ±rÄ±r.  \n  - `reset_index(drop=True)` ile yeni bir dÃ¼zenli indeks oluÅŸturulur.\n\n- **EÄŸitim / DoÄŸrulama / Test bÃ¶lÃ¼nmesi**:  \n  - `train_test_split` ile verinin %15â€™i test kÃ¼mesi olarak ayrÄ±lÄ±r.  \n  - Kalan %85â€™in iÃ§inden tekrar bÃ¶lÃ¼nerek yaklaÅŸÄ±k %15â€™i validasyon iÃ§in ayrÄ±lÄ±r.  \n  - `stratify` parametresi, her sÄ±nÄ±ftaki oranÄ±n tÃ¼m alt kÃ¼melerde korunmasÄ±nÄ± saÄŸlar.\n\n- **SÄ±nÄ±f bilgisi**:  \n  - `classes`: TÃ¼m Ã§iÃ§ek sÄ±nÄ±flarÄ±nÄ±n alfabetik listesi.  \n  - `class_to_idx`: Her sÄ±nÄ±fa bir numara atayan sÃ¶zlÃ¼k.  \n  - `num_classes`: Toplam sÄ±nÄ±f sayÄ±sÄ±.\n\n- **Kontrol Ã§Ä±ktÄ±larÄ±**:  \n  - Toplam gÃ¶rÃ¼ntÃ¼ sayÄ±sÄ± (`len(all_images)`).  \n  - Bulunan sÄ±nÄ±flar listesi (`classes`).\n\n> Bu hÃ¼cre sayesinde **ham gÃ¶rsel veriler dÃ¼zenlenir, etiketlenir ve model eÄŸitimine hazÄ±r hale gelir**.\n","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom pathlib import Path\n\nDATA_DIR = Path(\"/kaggle/input/flowers-recognition/flowers\") \nall_images = []\nfor ext in (\"*.jpg\",\"*.jpeg\",\"*.png\"): all_images += list(DATA_DIR.glob(f\"*/*{ext[1:]}\"))\nprint(\"GÃ¶rÃ¼ntÃ¼ sayÄ±sÄ±:\", len(all_images))\n\npaths  = [str(p) for p in all_images]\nlabels = [p.parent.name for p in all_images]\ndf = pd.DataFrame({\"path\": paths, \"label\": labels}).sample(frac=1, random_state=SEED).reset_index(drop=True)\n\nfrom sklearn.model_selection import train_test_split\ntrain_df, test_df = train_test_split(df, test_size=0.15, random_state=SEED, stratify=df[\"label\"])\ntrain_df, val_df  = train_test_split(train_df, test_size=0.15/(1-0.15), random_state=SEED, stratify=train_df[\"label\"])\n\nclasses = sorted(df[\"label\"].unique())\nclass_to_idx = {c:i for i,c in enumerate(classes)}\nnum_classes = len(classes)\nprint(\"SÄ±nÄ±flar:\", classes)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T21:03:23.823145Z","iopub.execute_input":"2025-09-25T21:03:23.823665Z","iopub.status.idle":"2025-09-25T21:03:24.182320Z","shell.execute_reply.started":"2025-09-25T21:03:23.823643Z","shell.execute_reply":"2025-09-25T21:03:24.181752Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 3) EÄŸitim Verisinin SÄ±nÄ±f DaÄŸÄ±lÄ±mÄ±\n\nBu hÃ¼cre, eÄŸitim kÃ¼mesindeki her Ã§iÃ§ek sÄ±nÄ±fÄ±nÄ±n kaÃ§ Ã¶rneÄŸe sahip olduÄŸunu **Ã§ubuk grafik** ile gÃ¶sterir.\n\n- `value_counts().plot(kind=\"bar\")` â†’ Her sÄ±nÄ±fÄ±n gÃ¶rÃ¼ntÃ¼ sayÄ±sÄ±nÄ± bar grafiÄŸe dÃ¶ker.  \n- `figsize`, `color`, `edgecolor` â†’ Grafik boyutu ve renk ayarlarÄ±.  \n- `set_title`, `set_xlabel`, `set_ylabel` â†’ BaÅŸlÄ±k ve eksen isimleri.  \n- `xticks(rotation=45)` â†’ SÄ±nÄ±f adlarÄ±nÄ± eÄŸerek okunabilirlik saÄŸlar.\n\n> Veri dengesini hÄ±zlÄ±ca gÃ¶rmek ve olasÄ± dengesizlikleri fark etmek iÃ§in kullanÄ±lÄ±r.\n","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nfig, ax = plt.subplots(figsize=(8,5))\ntrain_df[\"label\"].value_counts().plot(kind=\"bar\", ax=ax, color=\"skyblue\", edgecolor=\"black\")\nax.set_title(\"Train Set â€“ SÄ±nÄ±f DaÄŸÄ±lÄ±mÄ±\")\nax.set_xlabel(\"SÄ±nÄ±f\")\nax.set_ylabel(\"GÃ¶rÃ¼ntÃ¼ SayÄ±sÄ±\")\nplt.xticks(rotation=45)\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T21:03:28.828579Z","iopub.execute_input":"2025-09-25T21:03:28.829282Z","iopub.status.idle":"2025-09-25T21:03:29.186290Z","shell.execute_reply.started":"2025-09-25T21:03:28.829258Z","shell.execute_reply":"2025-09-25T21:03:29.185579Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 4) EÄŸitim Setinden Rastgele GÃ¶rseller\n\nBu hÃ¼cre, eÄŸitim kÃ¼mesinden **rastgele 15 gÃ¶rseli** tablo ÅŸeklinde gÃ¶sterir.\n\n- `random.sample` â†’ EÄŸitim verisinden 15 rastgele dosya yolu seÃ§er.  \n- `Image.open` â†’ Her gÃ¶rÃ¼ntÃ¼yÃ¼ okur ve ekranda gÃ¶sterir.  \n- `plt.subplots(3,5)` â†’ 3 satÄ±r 5 sÃ¼tunlu bir figÃ¼r alanÄ± oluÅŸturur.  \n- `ax.imshow` â†’ GÃ¶rÃ¼ntÃ¼yÃ¼ ilgili eksene Ã§izer.  \n- `ax.set_title` â†’ Her gÃ¶rselin Ã¼stÃ¼ne sÄ±nÄ±f adÄ±nÄ± (etiketini) yazar.  \n- `ax.axis(\"off\")` â†’ Eksen Ã§izgilerini kaldÄ±rÄ±r.  \n- `plt.suptitle` ve `plt.tight_layout` â†’ Genel baÅŸlÄ±k ekler, kenar boÅŸluklarÄ±nÄ± dÃ¼zenler.\n\n> Veri setinin iÃ§eriÄŸini hÄ±zlÄ±ca gÃ¶zden geÃ§irip **gÃ¶rsellerin Ã§eÅŸitliliÄŸini ve etiketlerin doÄŸruluÄŸunu** kontrol etmek iÃ§in kullanÄ±lÄ±r.\n","metadata":{}},{"cell_type":"code","source":"import random\nfrom PIL import Image\n\nfig, axes = plt.subplots(3, 5, figsize=(12,7))\nsample_paths = random.sample(train_df[\"path\"].tolist(), 15)\n\nfor ax, img_path in zip(axes.flat, sample_paths):\n    img = Image.open(img_path)\n    ax.imshow(img)\n    ax.set_title(Path(img_path).parent.name, fontsize=8)\n    ax.axis(\"off\")\n\nplt.suptitle(\"Train Set â€“ Rastgele 15 GÃ¶rsel\", fontsize=14)\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T21:03:33.601734Z","iopub.execute_input":"2025-09-25T21:03:33.602282Z","iopub.status.idle":"2025-09-25T21:03:34.846520Z","shell.execute_reply.started":"2025-09-25T21:03:33.602258Z","shell.execute_reply":"2025-09-25T21:03:34.845487Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 5) GÃ¶rsel Veri Seti HazÄ±rlÄ±ÄŸÄ± ve Veri ArtÄ±rma (Data Augmentation)\n\nBu hÃ¼cre, resimleri **modele uygun formata Ã§evirir** ve eÄŸitim sÄ±rasÄ±nda **veri artÄ±rma (data augmentation)** ile modeli genelleÅŸtirme gÃ¼cÃ¼ yÃ¼ksek hale getirir.\n\n### 5.1) Temel Ayarlar\n- **IMG_SIZE = 224** â†’ EfficientNet gibi Ã§oÄŸu Ã¶nceden eÄŸitilmiÅŸ modelin beklediÄŸi standart giriÅŸ boyutu.  \n- **BATCH = 32** â†’ Her eÄŸitim adÄ±mÄ±nda iÅŸlenecek gÃ¶rÃ¼ntÃ¼ sayÄ±sÄ±.  \n- **AUTO = tf.data.AUTOTUNE** â†’ TensorFlow, veri yÃ¼kleme ve Ã¶nbellekleme iÅŸlerini otomatik en iyi performansla yÃ¼rÃ¼tÃ¼r.\n\n### 5.2) GÃ¶rseli Okuma ve Ã–n Ä°ÅŸleme\n`decode_and_resize(path, label_idx)`  \n- Dosya yolundaki resmi okur (`tf.io.read_file`), RGB kanallarÄ±na Ã§evirir (`decode_image`).\n- Boyutunu 224Ã—224 piksele yeniden boyutlandÄ±rÄ±r (`tf.image.resize`).\n- Piksel deÄŸerlerini `float32` tipine Ã§evirir ve `preprocess_input` ile **[-1,1] aralÄ±ÄŸÄ±na** normalize eder.\n- Etiketi `one-hot` formuna dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r (Ã¶rneÄŸin 5 sÄ±nÄ±f varsa `[0,1,0,0,0]` gibi).\n\n### 5.3) Veri ArtÄ±rma KatmanÄ± (Data Augmentation)\n`aug` â†’ `keras.Sequential` ile oluÅŸturulan dÃ¶nÃ¼ÅŸÃ¼mler:\n- `layers.RandomFlip(mode=\"horizontal\")` â†’ GÃ¶rÃ¼ntÃ¼yÃ¼ rastgele yatay Ã§evirir.  \n- `layers.RandomRotation(factor=0.08)` â†’ Maksimum Â±%8 oranÄ±nda dÃ¶ndÃ¼rÃ¼r.  \n- `layers.RandomZoom(height_factor=0.1, width_factor=0.1)` â†’ YÃ¼kseklik ve geniÅŸlikte %10â€™a kadar yakÄ±nlaÅŸtÄ±rÄ±r.  \n- `layers.RandomContrast(factor=0.1)` â†’ KontrastÄ± %10 oranÄ±nda deÄŸiÅŸtirir.  \n\n> **AmaÃ§**: Modelin tek tip veriye aÅŸÄ±rÄ± uyum saÄŸlamasÄ±nÄ± (overfitting) Ã¶nlemek, gerÃ§ek dÃ¼nyadaki konum, Ä±ÅŸÄ±k ve poz deÄŸiÅŸikliklerine karÅŸÄ± **daha dayanÄ±klÄ±** hale getirmek.\n\n### 5.4) Veri KÃ¼mesi OluÅŸturma\n`make_ds(frame, training=False)`  \n- DataFrameâ€™den dosya yollarÄ± ve etiketleri alÄ±r.  \n- EÄŸitim modundaysa veriyi her epochâ€™ta rastgele karÄ±ÅŸtÄ±rÄ±r.  \n- GÃ¶rselleri `decode_and_resize` ile iÅŸler, eÄŸitim modunda `augment_if_training` ile veri artÄ±rÄ±r.  \n- Veriyi `batch` ve `prefetch` ile hÄ±zlandÄ±rÄ±r.\n\n### 5.5) SonuÃ§ Datasetâ€™leri\n- `train_ds` â†’ Veri artÄ±rma uygulanmÄ±ÅŸ eÄŸitim kÃ¼mesi.  \n- `val_ds`   â†’ DoÄŸrulama (modeli deÄŸerlendirirken veri artÄ±rma yok).  \n- `test_ds`  â†’ Test kÃ¼mesi.\n\n> Bu adÄ±m, gÃ¶rselleri **standart boyut ve Ã¶lÃ§eÄŸe getirir**, veri artÄ±rma ile Ã§eÅŸitlendirir ve modeli **daha kararlÄ± ve genelleme yeteneÄŸi yÃ¼ksek** hale getirir.\n","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.applications.efficientnet import preprocess_input\nfrom tensorflow.keras import layers\n\nIMG_SIZE = 224\nBATCH    = 32\nAUTO     = tf.data.AUTOTUNE\n\ndef decode_and_resize(path, label_idx):\n    img = tf.io.read_file(path)\n    img = tf.io.decode_image(img, channels=3, expand_animations=False)\n    img = tf.image.resize(img, (IMG_SIZE, IMG_SIZE), method=tf.image.ResizeMethod.BILINEAR)\n    img = tf.cast(img, tf.float32)\n    img = preprocess_input(img)   # [-1,1]\n    y = tf.one_hot(label_idx, depth=num_classes)\n    return img, y\n\naug = tf.keras.Sequential(\n    [\n        layers.RandomFlip(mode=\"horizontal\"),     \n        layers.RandomRotation(factor=0.08),        \n        layers.RandomZoom(height_factor=0.1, width_factor=0.1),\n        layers.RandomContrast(factor=0.1),\n    ], name=\"augment\")\n\ndef augment_if_training(img, y):\n    return aug(img, training=True), y\n\ndef make_ds(frame, training=False):\n    paths = frame[\"path\"].values\n    labs  = frame[\"label\"].map(class_to_idx).values\n    ds = tf.data.Dataset.from_tensor_slices((paths, labs))\n    if training: ds = ds.shuffle(len(frame), seed=SEED, reshuffle_each_iteration=True)\n    ds = ds.map(decode_and_resize, num_parallel_calls=AUTO)\n    if training: ds = ds.map(augment_if_training, num_parallel_calls=AUTO)\n    ds = ds.batch(BATCH).prefetch(AUTO)\n    return ds\n\ntrain_ds = make_ds(train_df, training=True)\nval_ds   = make_ds(val_df,   training=False)\ntest_ds  = make_ds(test_df,  training=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T21:03:40.634217Z","iopub.execute_input":"2025-09-25T21:03:40.634500Z","iopub.status.idle":"2025-09-25T21:03:43.160706Z","shell.execute_reply.started":"2025-09-25T21:03:40.634479Z","shell.execute_reply":"2025-09-25T21:03:43.160162Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 6) Veri ArtÄ±rma (Augmentation) SonuÃ§larÄ±nÄ±n GÃ¶rselleÅŸtirilmesi\n\nBu hÃ¼cre, eÄŸitim kÃ¼mesinden alÄ±nan bir batch (toplu) veride **uygulanmÄ±ÅŸ rastgele artÄ±rma iÅŸlemlerini** gÃ¶rsel olarak gÃ¶sterir.\n\n- `train_ds.take(1)` â†’ EÄŸitim veri kÃ¼mesinden tek bir batch Ã§eker.  \n- `x_aug` â†’ Veri artÄ±rma uygulanmÄ±ÅŸ gÃ¶rÃ¼ntÃ¼ler; `numpy().astype(np.uint8)` ile gÃ¶rÃ¼ntÃ¼ formatÄ±na dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼r.  \n- `k = min(8, x_show.shape[0])` â†’ Ä°lk 8 gÃ¶rÃ¼ntÃ¼ seÃ§ilir.  \n- `plt.subplot(2,4,i+1)` ve `plt.imshow` â†’ 2 satÄ±r 4 sÃ¼tunlu bir tabloya her gÃ¶rÃ¼ntÃ¼ yerleÅŸtirilir.  \n- `plt.axis('off')` â†’ Eksen Ã§izgileri kaldÄ±rÄ±lÄ±r.  \n- `plt.suptitle` ve `plt.tight_layout` â†’ Genel baÅŸlÄ±k ekler, dÃ¼zenli gÃ¶rÃ¼nÃ¼m saÄŸlar.\n\n> Bu gÃ¶rselleÅŸtirme ile **RandomFlip, RandomRotation, RandomZoom, RandomContrast** gibi veri artÄ±rma adÄ±mlarÄ±nÄ±n resimlere nasÄ±l uygulandÄ±ÄŸÄ± doÄŸrudan gÃ¶rÃ¼lebilir.\n","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\n\nfor x_aug, yb in train_ds.take(1):\n    x_show = x_aug.numpy().astype(np.uint8)\n    break\n\nk = min(8, x_show.shape[0])\nplt.figure(figsize=(12,6))\nfor i in range(k):\n    plt.subplot(2,4,i+1)\n    plt.imshow(x_show[i])\n    plt.axis('off')\nplt.suptitle(\"Augmentation Ã¶rnekleri\")\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T21:03:51.948330Z","iopub.execute_input":"2025-09-25T21:03:51.948919Z","iopub.status.idle":"2025-09-25T21:03:52.980331Z","shell.execute_reply.started":"2025-09-25T21:03:51.948896Z","shell.execute_reply":"2025-09-25T21:03:52.979428Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 7) Model Kurulumu, Derleme ve Callbackâ€™ler\n\nBu hÃ¼cre, **EfficientNetB0 tabanlÄ± bir transfer Ã¶ÄŸrenme modeli** kurar, uygun kayÄ±p/optimizasyon ayarlarÄ±yla derler ve eÄŸitimde kullanÄ±lacak **callback**â€™leri hazÄ±rlar.\n\n### ğŸ”© Mimari (Transfer Learning)\n- `EfficientNetB0(include_top=False, weights=\"imagenet\")`  \n  - **Ã–n-eÄŸitimli** (ImageNet) taban; tepe (classification) katmanÄ± Ã§Ä±karÄ±lmÄ±ÅŸtÄ±r.\n\n- AkÄ±ÅŸ:\n  1. **Input**: `(224,224,3)`\n  2. **base(inputs, training=False)**: BatchNorm dalgalanmalarÄ±nÄ± Ã¶nlemek iÃ§in Ã§Ä±karÄ±m modunda Ã§aÄŸrÄ±lÄ±r.\n  3. **GlobalAveragePooling2D**: Ã–zellik haritalarÄ±nÄ± vektÃ¶re indirger, parametre sayÄ±sÄ±nÄ± azaltÄ±r.\n  4. **Dropout(0.4)**: AÅŸÄ±rÄ± uyumu (overfitting) azaltÄ±r.\n  5. **Dense(num_classes, softmax)**: SÄ±nÄ±f olasÄ±lÄ±klarÄ±nÄ± Ã¼retir.  \n     - `l2` verilirse `kernel_regularizer=l2(...)` ile **aÄŸÄ±rlÄ±k cezalandÄ±rma** eklenir.\n\n### ğŸ§ª Derleme (Loss & Optimizer)\n- **Loss**: `CategoricalCrossentropy(label_smoothing=...)`  \n  - `label_smoothing`: Ã‡ok gÃ¼venli tahminleri yumuÅŸatÄ±r, genellemeye yardÄ±mcÄ± olabilir (varsayÄ±lan 0.0).\n- **Optimizer**:  \n  - `\"adam\"` â†’ `Adam(lr)`: HÄ±zlÄ± yakÄ±nsama, genelde iyi varsayÄ±lan.  \n  - Aksi halde `SGD(lr, momentum=0.9, nesterov=True)`: Daha kontrollÃ¼ gÃ¼ncellemeler.\n\n### â±ï¸ Callbackâ€™ler\n- `ModelCheckpoint(\"best_stage1.keras\", monitor=\"val_accuracy\", mode=\"max\", save_best_only=True)`  \n  - **En iyi doÄŸrulama baÅŸarÄ±mÄ±** yakalandÄ±ÄŸÄ±nda aÄŸÄ±rlÄ±klarÄ± kaydeder (Stage-1).  \n- `EarlyStopping(monitor=\"val_accuracy\", patience=5, restore_best_weights=True)`  \n  - Ä°yileÅŸme durunca eÄŸitimi erken durdurur; **en iyi aÄŸÄ±rlÄ±klara** geri dÃ¶ner.\n- `ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=2, min_lr=1e-7)`  \n  - KayÄ±p iyileÅŸmiyorsa Ã¶ÄŸrenme oranÄ±nÄ± **yarÄ±ya indirir** (plateauâ€™da daha ince ayar).\n\n### â–¶ï¸ Stage-1 EÄŸitimi\n- `build_model(dropout=0.4, base_trainable=False)` ile tabanÄ± dondurulmuÅŸ model kurulur.  \n- `compile_with(model, lr=1e-3, opt=\"adam\")` ile uygun Ã¶ÄŸrenme oranÄ± ve optimizer ayarlanÄ±r.  \n- `model.summary()` mimariyi Ã¶zetler.","metadata":{}},{"cell_type":"code","source":"\nfrom tensorflow.keras import layers, models, regularizers\nfrom tensorflow.keras.applications import EfficientNetB0\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n\ndef build_model(dropout=0.4, l2=None, base_trainable=False):\n    base = EfficientNetB0(include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3), weights=\"imagenet\")\n    base.trainable = base_trainable\n    inputs = layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3), name=\"input_preprocessed\")\n    x = base(inputs, training=False)\n    x = layers.GlobalAveragePooling2D()(x)\n    x = layers.Dropout(dropout)(x)\n    kw = {} if l2 is None else {\"kernel_regularizer\": regularizers.l2(l2)}\n    outputs = layers.Dense(num_classes, activation=\"softmax\", **kw)(x)\n    return models.Model(inputs, outputs, name=\"flowers_effnetb0\")\n\ndef compile_with(model, lr, opt=\"adam\", label_smoothing=0.0):\n    loss = tf.keras.losses.CategoricalCrossentropy(label_smoothing=label_smoothing)\n    optimizer = tf.keras.optimizers.Adam(lr) if opt==\"adam\" else tf.keras.optimizers.SGD(lr, momentum=0.9, nesterov=True)\n    model.compile(optimizer=optimizer, loss=loss, metrics=[\"accuracy\"])\n    return model\n\nckpt1 = ModelCheckpoint(\"best_stage1.keras\", monitor=\"val_accuracy\", save_best_only=True, mode=\"max\")\nes    = EarlyStopping(monitor=\"val_accuracy\", patience=5, restore_best_weights=True)\nrlr   = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=2, min_lr=1e-7)\nmodel = build_model(dropout=0.4, base_trainable=False)\ncompile_with(model, lr=1e-3, opt=\"adam\")\nprint(model.summary())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T21:04:01.840634Z","iopub.execute_input":"2025-09-25T21:04:01.840884Z","iopub.status.idle":"2025-09-25T21:04:04.008691Z","shell.execute_reply.started":"2025-09-25T21:04:01.840868Z","shell.execute_reply":"2025-09-25T21:04:04.008161Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 8) Model Mimarisi GÃ¶rselleÅŸtirme\n\nBu hÃ¼cre, kurulmuÅŸ olan **derin Ã¶ÄŸrenme modelinin yapÄ±sÄ±nÄ± resim dosyasÄ± olarak kaydeder**.\n\n- `plot_model(model, to_file=\"model_architecture.png\")` â†’ Model mimarisini `model_architecture.png` adÄ±yla kaydeder.  \n- `show_shapes=True` â†’ Her katmanÄ±n giriÅŸ/Ã§Ä±kÄ±ÅŸ boyutlarÄ±nÄ± gÃ¶sterir.  \n- `show_layer_names=True` â†’ Katman isimlerini diyagrama ekler.\n","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.utils import plot_model\n\nplot_model(model, to_file=\"model_architecture.png\",\n           show_shapes=True, show_layer_names=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T21:04:08.740800Z","iopub.execute_input":"2025-09-25T21:04:08.741412Z","iopub.status.idle":"2025-09-25T21:04:08.996899Z","shell.execute_reply.started":"2025-09-25T21:04:08.741386Z","shell.execute_reply":"2025-09-25T21:04:08.996141Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 9) Model EÄŸitimi\n\nBu hÃ¼cre, EfficientNet tabanlÄ± modelin **sÄ±nÄ±flandÄ±rma katmanlarÄ±nÄ± eÄŸitir.** \n\n- **`model.fit` parametreleri**  \n  - `train_ds` â†’ EÄŸitim verisi.  \n  - `validation_data=val_ds` â†’ Her epoch sonunda doÄŸrulama kÃ¼mesinde Ã¶lÃ§Ã¼m yapÄ±lÄ±r.  \n  - `epochs=15` â†’ Maksimum 15 eÄŸitim turu.  \n  - `callbacks=[ckpt1, es, rlr]` â†’  \n    - `ckpt1`: En iyi doÄŸrulama doÄŸruluÄŸunda modeli kaydeder.  \n    - `es`: Ä°yileÅŸme durursa erken durdurur ve en iyi aÄŸÄ±rlÄ±klarÄ± geri yÃ¼kler.  \n    - `rlr`: DoÄŸrulama kaybÄ± iyileÅŸmezse Ã¶ÄŸrenme oranÄ±nÄ± otomatik yarÄ±ya indirir.\n  - `verbose=1` â†’ Her epoch iÃ§in ilerleme Ã§ubuÄŸu ve metrikler gÃ¶sterilir.\n\n- **`hist1` Ã§Ä±ktÄ±sÄ±**  \n  - EÄŸitim sÃ¼resince **kayÄ±p (loss)** ve **doÄŸruluk (accuracy)** deÄŸerlerini kaydeder.  \n  - Bu bilgiler, sonraki adÄ±mda grafik Ã§izerek modelin **Ã¶ÄŸrenme eÄŸrisini** incelemek iÃ§in kullanÄ±lÄ±r.\n\n> Bu aÅŸama, Ã¶nceden eÄŸitilmiÅŸ EfficientNet tabanÄ±nÄ± deÄŸiÅŸtirmeden  Ã¼st sÄ±nÄ±flandÄ±rÄ±cÄ± katmanÄ±nÄ± eÄŸiterek **hÄ±zlÄ± ve stabil bir eÄŸitim yapÄ±labilmesini saÄŸlar**.\n","metadata":{}},{"cell_type":"code","source":"hist1 = model.fit(\n    train_ds,\n    validation_data=val_ds,\n    epochs=15,\n    callbacks=[ckpt1, es, rlr],\n    verbose=1\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T21:04:16.278879Z","iopub.execute_input":"2025-09-25T21:04:16.279184Z","iopub.status.idle":"2025-09-25T21:09:41.658845Z","shell.execute_reply.started":"2025-09-25T21:04:16.279158Z","shell.execute_reply":"2025-09-25T21:09:41.658029Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 10) Ã–ÄŸrenme EÄŸrileri (KÄ±sa, Net, DetaylÄ±)\n\n**AmaÃ§**\n- EÄŸitim/validasyon **accuracy** ve **loss** eÄŸrilerini Ã§izmek, son epochâ€™lara bakarak **overfitting/plato** sinyallerini otomatik yorumlamak.\n\n**Fonksiyonlar**\n- `plot_history(h, title)`:  \n  - Solda: `accuracy` (train vs val)  \n  - SaÄŸda: `loss` (train vs val)\n- `comment_learning_curves(history, tail=5)`:  \n  - Son `k=tail` epoch ortalamalarÄ±na gÃ¶re farklarÄ± hesaplar:\n    - `acc_gap = mean(train_acc - val_acc)`  \n      - `> 0.02` â†’ **Overfitting** ihtimali  \n      - `â‰ˆ 0` â†’ **Genelleme** iyi  \n    - `loss_gap = mean(val_loss - train_loss)`  \n      - Pozitif ve bÃ¼yÃ¼k â†’ **Overfitting** riski\n  - **Plato**: Son `k` epochâ€™ta `val_acc` artÄ±ÅŸÄ± `< 0.005` ise uyarÄ±r.\n\n**Ã–neri ÅablonlarÄ± (Duruma GÃ¶re)**\n- Overfitting: **Daha gÃ¼Ã§lÃ¼ augmentation**, **Dropout/L2â†‘**, **LRâ†“**, **EarlyStopping** sÄ±kÄ±laÅŸtÄ±r.\n- Plato: **ReduceLROnPlateau**, gerekirse **kÃ¼Ã§Ã¼k LR ile Ã¼st katmanlarÄ± fine-tune** et.\n- Val > Train: BirkaÃ§ epoch daha dene; **LR Ä±sÄ±nma/plateau** stratejisini gÃ¶zden geÃ§ir.\n","metadata":{}},{"cell_type":"code","source":"\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n\ndef plot_history(h, title):\n    plt.figure(figsize=(12,4))\n    # Acc\n    plt.subplot(1,2,1)\n    plt.plot(h.history[\"accuracy\"], label=\"train_acc\")\n    plt.plot(h.history[\"val_accuracy\"], label=\"val_acc\")\n    plt.title(f\"{title} - Accuracy\"); plt.grid(True); plt.legend()\n    # Loss\n    plt.subplot(1,2,2)\n    plt.plot(h.history[\"loss\"], label=\"train_loss\")\n    plt.plot(h.history[\"val_loss\"], label=\"val_loss\")\n    plt.title(f\"{title} - Loss\"); plt.grid(True); plt.legend()\n    plt.show()\n\nplot_history(hist1, \"Stage-1\")\n\n\ndef comment_learning_curves(history, tail=5):\n    h = history.history\n    acc  = np.array(h.get(\"accuracy\", []), dtype=float)\n    val_acc = np.array(h.get(\"val_accuracy\", []), dtype=float)\n    loss = np.array(h.get(\"loss\", []), dtype=float)\n    val_loss = np.array(h.get(\"val_loss\", []), dtype=float)\n\n    if len(val_acc)==0 or len(acc)==0:\n        print(\"Not: accuracy/val_accuracy bulunamadÄ±; yorum atlandÄ±.\")\n        return\n\n    # Son k epoch ortalamalarÄ± & farklar\n    k = min(tail, len(acc))\n    acc_gap  = float(np.nanmean(acc[-k:] - val_acc[-k:]))   # pozitifse overfit ihtimali\n    loss_gap = float(np.nanmean(val_loss[-k:] - loss[-k:])) if len(val_loss)==len(loss)>0 else np.nan\n\n    # Basit plato gÃ¶stergesi: son k adÄ±mda val_acc artÄ±ÅŸÄ± Ã§ok kÃ¼Ã§Ã¼kse\n    plateau = (np.nanmax(val_acc) - np.nanmin(val_acc[-k:])) < 0.005\n\n    lines = []\n    lines.append(f\"Ã–zet: Son {k} epoch ortalamasÄ±nda accuracy farkÄ± (train - val) â‰ˆ {acc_gap:.3f}.\")\n\n    if acc_gap > 0.02:\n        lines.append(\"Yorum: Train doÄŸruluÄŸu belirgin ÅŸekilde daha yÃ¼ksek â†’ **overfitting** iÅŸareti.\")\n        lines.append(\"Ã–neri: Augmentationâ€™Ä± gÃ¼Ã§lendir, Dropout/L2 ekle/artÄ±r, LRâ€™Ä± azalt veya erken durdurmayÄ± sÄ±kÄ±laÅŸtÄ±r.\")\n    elif acc_gap < -0.01:\n        lines.append(\"Yorum: Val doÄŸruluÄŸu trainâ€™den yÃ¼ksek gÃ¶rÃ¼nÃ¼yor; muhtemelen data shuffle/batch etkisi.\")\n        lines.append(\"Ã–neri: BirkaÃ§ epoch daha eÄŸitip dengele; LR warmup/plateau stratejisini gÃ¶zden geÃ§ir.\")\n    else:\n        lines.append(\"Yorum: Train/Val eÄŸrileri yakÄ±n seyrediyor â†’ **genelleme** kabul edilebilir dÃ¼zeyde.\")\n\n    if plateau:\n        lines.append(\"Not: Val accuracy son dÃ¶nemde plato yaptÄ±.\")\n        lines.append(\"Ã–neri: ReduceLROnPlateau/TTA veya alt katmanlarÄ±n bir bÃ¶lÃ¼mÃ¼nÃ¼ aÃ§Ä±p kÃ¼Ã§Ã¼k LR ile fine-tuning dene.\")\n\n    if not np.isnan(loss_gap):\n        lines.append(f\"Loss farkÄ± (val - train) â‰ˆ {loss_gap:.3f}. Pozitif ve bÃ¼yÃ¼kse overfit riski artar.\")\n\n    print(\"\\n\".join(lines))\n\ncomment_learning_curves(hist1, tail=5)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T21:09:46.973234Z","iopub.execute_input":"2025-09-25T21:09:46.973518Z","iopub.status.idle":"2025-09-25T21:09:47.281599Z","shell.execute_reply.started":"2025-09-25T21:09:46.973497Z","shell.execute_reply":"2025-09-25T21:09:47.280696Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 11) EÄŸitim Ã–zeti â€“ En Ä°yi Epoch ve Son DeÄŸerler\n\nBu hÃ¼cre, her eÄŸitim aÅŸamasÄ±nÄ±n **en iyi doÄŸrulama baÅŸarÄ±mÄ±nÄ± ve son metriklerini kÄ±saca raporlar.**\n\n**Fonksiyon**\n- `summarize_curves(history)`:\n  - `best_val_acc` : En yÃ¼ksek doÄŸrulama doÄŸruluÄŸu (val_accuracy) ve gerÃ§ekleÅŸtiÄŸi epoch.\n  - `last_train_acc` : Son epochâ€™taki eÄŸitim doÄŸruluÄŸu.\n  - `last_val_loss` : Son epochâ€™taki doÄŸrulama kaybÄ±.\n  - Yorum: EÄŸer **train_acc â‰« val_acc** ise **overfitting** riski vurgulanÄ±r. AyrÄ±ca LR dÃ¼ÅŸÃ¼ÅŸÃ¼ (ReduceLROnPlateau) sonrasÄ± val_lossâ€™un iyileÅŸmesi olumlu olarak not edilir.\n","metadata":{}},{"cell_type":"code","source":"def summarize_curves(history):\n    import numpy as np\n    h = history.history\n    best_val_acc = float(np.max(h.get(\"val_accuracy\", [0.0])))\n    best_val_epoch = int(np.argmax(h.get(\"val_accuracy\", [0.0]))) + 1\n    last_train_acc = float(h.get(\"accuracy\", [0.0])[-1]) if \"accuracy\" in h else float('nan')\n    last_val_loss  = float(h.get(\"val_loss\", [0.0])[-1])  if \"val_loss\"  in h else float('nan')\n    print(\n        f\"[Ã–zet] En iyi val_acc: {best_val_acc:.4f} (epoch {best_val_epoch}) | \"\n        f\"Son train_acc: {last_train_acc:.4f} | Son val_loss: {last_val_loss:.4f}\"\n    )\n\nsummarize_curves(hist1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T21:09:53.757454Z","iopub.execute_input":"2025-09-25T21:09:53.758176Z","iopub.status.idle":"2025-09-25T21:09:53.763866Z","shell.execute_reply.started":"2025-09-25T21:09:53.758115Z","shell.execute_reply":"2025-09-25T21:09:53.763040Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 12) Test DeÄŸerlendirme (Tam SÃ¼rÃ¼m)\n\nBu hÃ¼cre, **test kÃ¼mesi performansÄ±nÄ±** ayrÄ±ntÄ±lÄ± raporlar ve **confusion matrix** gÃ¶rselleÅŸtirir.\n\n**AdÄ±mlar**\n- **GerÃ§ek etiketler (`y_true`)**: `test_ds` batchâ€™lerindeki **one-hot** etiketler `argmax` ile sÄ±nÄ±f indeksine Ã§evrilerek tek dizide birleÅŸtirilir.\n- **Tahminler (`y_pred`)**: `model.predict(test_ds)` Ã§Ä±ktÄ±sÄ±ndan **en yÃ¼ksek olasÄ±lÄ±klÄ± sÄ±nÄ±f** `argmax` ile seÃ§ilir (isteÄŸe baÄŸlÄ±: `y_pred_probs` analiz iÃ§in saklanÄ±r).\n- **SÄ±nÄ±flandÄ±rma raporu**: `classification_report` â†’ **precision, recall, f1-score** ve support (sÄ±nÄ±f baÅŸÄ±na Ã¶rnek sayÄ±sÄ±).\n- **Confusion matrix**: `confusion_matrix` ile Ã¼retilir; sÄ±caklÄ±k haritasÄ± olarak Ã§izilir ve hÃ¼cre iÃ§ine sayÄ±lar yazÄ±lÄ±r.\n  - `thr = cm.max() / 2` â†’ Metin rengi kontrast iÃ§in otomatik seÃ§ilir (bÃ¼yÃ¼k hÃ¼crelerde **beyaz**, kÃ¼Ã§Ã¼klerde **siyah**).\n\n**Yorumlama Ä°puÃ§larÄ±**\n- **Diagonal (True=Pred)** hÃ¼creler yÃ¼ksekse model doÄŸru sÄ±nÄ±flarÄ± iyi yakalÄ±yor demektir.\n- AynÄ± satÄ±rda **yanlÄ±ÅŸ tahmin edilen sÃ¼tunlar** â†’ o gerÃ§ek sÄ±nÄ±fÄ±n karÄ±ÅŸtÄ±ÄŸÄ± sÄ±nÄ±flarÄ± gÃ¶sterir (sistematik hata/benzer sÄ±nÄ±flar).\n- **Macro vs Weighted F1**: SÄ±nÄ±f dengesizliÄŸi varsa `weighted f1` daha temsilÃ®, `macro f1` sÄ±nÄ±flarÄ± **eÅŸit aÄŸÄ±rlÄ±klÄ±** deÄŸerlendirir.\n- DÃ¼ÅŸÃ¼k kalan sÄ±nÄ±flar iÃ§in: **augmentation Ã§eÅŸitliliÄŸi**, **sÄ±nÄ±f aÄŸÄ±rlÄ±klarÄ±** veya **daha fazla veri** deÄŸerlendirilebilir.\n\n**Ã‡Ä±ktÄ±lar**\n- Konsolda ayrÄ±ntÄ±lÄ± metrik tablosu.\n- Etiket isimleriyle dÃ¶ndÃ¼rÃ¼lmÃ¼ÅŸ eksenli, Ã¼stÃ¼nde deÄŸer yazan **confusion matrix** grafiÄŸi.\n","metadata":{}},{"cell_type":"code","source":"\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport itertools\nimport seaborn as sns\n\n# --- y_true: batch'lerden toplanÄ±r ---\ny_true_batches = []\nfor _, y in test_ds:\n    y_true_batches.append(np.argmax(y.numpy(), axis=1))\ny_true = np.concatenate(y_true_batches, axis=0)\n\n# --- y_pred: model tahmini ---\ny_pred_probs = model.predict(test_ds, verbose=0)\ny_pred = np.argmax(y_pred_probs, axis=1)\n\n# --- Rapor ---\nprint(classification_report(y_true, y_pred, target_names=classes, digits=4))\n\n# --- Confusion Matrix ---\ncm = confusion_matrix(y_true, y_pred)\nplt.figure(figsize=(7,6))\nsns.heatmap(cm, annot=True, fmt=\"d\", cbar=False, \n            xticklabels=classes, yticklabels=classes)\nplt.ylabel(\"GerÃ§ek\")\nplt.xlabel(\"Tahmin\")\nplt.title(\"Confusion Matrix\")\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T21:10:00.592654Z","iopub.execute_input":"2025-09-25T21:10:00.592929Z","iopub.status.idle":"2025-09-25T21:10:16.833164Z","shell.execute_reply.started":"2025-09-25T21:10:00.592907Z","shell.execute_reply":"2025-09-25T21:10:16.832407Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 13) Final Test Accuracy (Tek SatÄ±r SonuÃ§)\n\nBu hÃ¼cre, **test kÃ¼mesindeki genel doÄŸruluk (accuracy)** deÄŸerini tek satÄ±rda verir.\n\n- `y_true_vec` ve `y_pred_vec` : GerÃ§ek ve tahmin sÄ±nÄ±f indeksleri (tek boyutlu vektÃ¶rler).  \n- `(y_true_vec == y_pred_vec).mean()` : DoÄŸru tahmin oranÄ±nÄ± hesaplar.  \n- `print(f\"Test Accuracy: {test_acc:.4f}\")` : DÃ¶rt ondalÄ±k hassasiyetle ekrana yazdÄ±rÄ±r.\n\n> Bu metrik, projenin **nihai baÅŸarÄ± yÃ¼zdesini** hÄ±zlÄ±ca Ã¶zetler ve raporlarda temel performans gÃ¶stergesi olarak kullanÄ±labilir.\n","metadata":{}},{"cell_type":"code","source":"import numpy as np\n\ny_true_vec = np.asarray(y_true).squeeze()\ny_pred_vec = np.asarray(y_pred).squeeze()\n\ntest_acc = (y_true_vec == y_pred_vec).mean()\nprint(f\"Test Accuracy: {test_acc:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T21:10:31.931084Z","iopub.execute_input":"2025-09-25T21:10:31.931378Z","iopub.status.idle":"2025-09-25T21:10:31.935939Z","shell.execute_reply.started":"2025-09-25T21:10:31.931357Z","shell.execute_reply":"2025-09-25T21:10:31.935166Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 14) Eigen-CAM ile GÃ¶rselleÅŸtirme\n\nBu hÃ¼cre, **modelin karar verirken gÃ¶rÃ¼ntÃ¼nÃ¼n hangi bÃ¶lgelerine odaklandÄ±ÄŸÄ±nÄ±** gÃ¶sterir. Grad-CAMâ€™e benzer, ancak **Ã¶zdeÄŸer (eigen) ayrÄ±ÅŸÄ±mÄ±** ile en baskÄ±n Ã¶zellikleri yakalar.\n\n**AdÄ±mlar**\n- `base = model.get_layer(\"efficientnetb0\")` â†’ EfficientNetB0 taban katmanÄ±nÄ± alÄ±r.\n- `_to_uint8_rgb` â†’ GÃ¶rÃ¼ntÃ¼yÃ¼ `[0,255]` aralÄ±ÄŸÄ±nda `uint8` formatÄ±na Ã§evirir.\n- `eigen_cam_batch` fonksiyonu:\n  1. Ã–zellik haritalarÄ±nÄ± (`feats`) Ã§Ä±karÄ±r.\n  2. Kovaryans matrisinin en bÃ¼yÃ¼k Ã¶zdeÄŸerine karÅŸÄ±lÄ±k gelen vektÃ¶rle **en baskÄ±n Ã¶zellik yÃ¶nÃ¼nÃ¼** bulur.\n  3. Bu yÃ¶nÃ¼ Ä±sÄ± haritasÄ±na (heatmap) dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r.\n  4. Orijinal gÃ¶rÃ¼ntÃ¼ Ã¼zerine yarÄ± saydam olarak bindirir (`alpha=0.35`).\n\n**KullanÄ±m**\n- `for xb, yb in test_ds.take(1)` â†’ Test setinden ilk batchâ€™i alÄ±r, ilk 5 gÃ¶rÃ¼ntÃ¼yÃ¼ iÅŸler.\n- Yan yana iki gÃ¶rsel Ã§izilir:\n  - **Input**: Orijinal resim.\n  - **Eigen-CAM**: Modelin en Ã§ok dikkate aldÄ±ÄŸÄ± alanlarÄ± gÃ¶steren Ä±sÄ± haritasÄ±.\n\n> Bu yÃ¶ntem, modelin **hangi piksellerden Ã¶ÄŸrenme yaptÄ±ÄŸÄ±** ve **hangi bÃ¶lgelere odaklandÄ±ÄŸÄ±** hakkÄ±nda sezgisel ve gÃ¶rsel bir aÃ§Ä±klama sunar. \n","metadata":{}},{"cell_type":"code","source":"\nimport tensorflow as tf, numpy as np, cv2, matplotlib.pyplot as plt\n\ntry:\n    base \nexcept NameError:\n    base = model.get_layer(\"efficientnetb0\") \n\n\ndef _to_uint8_rgb(img_tf):\n    \"\"\"img_tf: tf.Tensor (H,W,3) float/uint8; range [-1,1] veya [0,1] veya [0,255] olabilir.\n       return: np.uint8 [0,255], RGB\n    \"\"\"\n    x = img_tf.numpy()\n    if x.dtype != np.uint8:\n        x = x.astype(np.float32)\n        vmin, vmax = x.min(), x.max()\n       \n        if vmax <= 1.0 and vmin >= -1.0:     \n            if vmin < 0:  # [-1,1]\n                x = (x + 1.0) * 127.5\n            else:         # [0,1]\n                x = x * 255.0\n    \n        x = np.clip(x, 0, 255)\n    return x.astype(np.uint8)  \n\ndef eigen_cam_batch(x_imgs, alpha=0.35):\n    feats = base(x_imgs, training=False)        \n    B, Hc, Wc, C = feats.shape\n    outs = []\n\n    for b in range(B):\n        F   = feats[b]                       \n        F2d = tf.reshape(F, [-1, C])          \n        X   = F2d - tf.reduce_mean(F2d, axis=0, keepdims=True)\n        cov = tf.matmul(X, X, transpose_a=True) / tf.cast(tf.shape(X)[0]-1, tf.float32)\n        _, eigvecs = tf.linalg.eigh(cov)\n        w   = eigvecs[:, -1]                   \n        h   = tf.reshape(tf.matmul(X, w[:, None]), [Hc, Wc])\n        h   = tf.maximum(h, 0)\n        h   = (h - tf.reduce_min(h)) / (tf.reduce_max(h) - tf.reduce_min(h) + 1e-12)\n\n        img = _to_uint8_rgb(x_imgs[b])          \n\n        heat = cv2.resize(h.numpy(), (img.shape[1], img.shape[0]))\n        heat = (255*heat).astype(np.uint8)\n        heat = cv2.applyColorMap(heat, cv2.COLORMAP_JET)          \n        heat = cv2.cvtColor(heat, cv2.COLOR_BGR2RGB)           \n        vis  = cv2.addWeighted(heat, alpha, img, 1-alpha, 0)\n\n        outs.append((img, vis))\n    return outs\n\nfor xb, _ in test_ds.take(1):\n    arr = xb[0].numpy()\n    print(\"dtype:\", arr.dtype, \"min/max:\", arr.min(), arr.max())\n\n# --- Ã–RNEK KULLANIM (test setinden 5 gÃ¶rsel) ---\nfor xb, yb in test_ds.take(1):\n    k = min(5, xb.shape[0])\n    res = eigen_cam_batch(xb[:k])\n    for i, (img, vis) in enumerate(res):\n        plt.figure(figsize=(5,3))\n        plt.subplot(1,2,1); plt.imshow(img); plt.axis('off'); plt.title('Input')\n        plt.subplot(1,2,2); plt.imshow(vis); plt.axis('off'); plt.title('Eigen-CAM')\n        plt.tight_layout(); plt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T21:10:35.696170Z","iopub.execute_input":"2025-09-25T21:10:35.696851Z","iopub.status.idle":"2025-09-25T21:10:38.337462Z","shell.execute_reply.started":"2025-09-25T21:10:35.696824Z","shell.execute_reply":"2025-09-25T21:10:38.336784Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 15) Grad-CAM ile AÃ§Ä±klanabilirlik (Base + Head Manuel Zincir)\n\nBu hÃ¼cre, **base Ã¶zellik haritasÄ±** Ã¼zerinden **headâ€™i (sÄ±nÄ±flandÄ±rÄ±cÄ± kÄ±smÄ±)** elle Ã§aÄŸÄ±rarak Grad-CAM Ä±sÄ± haritasÄ± Ã¼retir. BÃ¶ylece `model.input` sorunlu/None olsa bile Ã§alÄ±ÅŸÄ±r; Eigen-CAM ile aynÄ± batch (`xb`) Ã¼zerinde kullanÄ±labilir.\n\n### Ana Fikir\n- **Base (EfficientNetB0)**: KonvolÃ¼syonel Ã¶zellik haritalarÄ±nÄ± Ã¼retir.\n- **Head (GAP + Dropout + Dense)**: SÄ±nÄ±f olasÄ±lÄ±klarÄ±nÄ± hesaplar. Burada headâ€™i **katman katman** kendimiz uygularÄ±z.\n- **Grad-CAM**: Hedef sÄ±nÄ±f skorunun, son konvolÃ¼syon Ã§Ä±kÄ±ÅŸÄ±na gÃ¶re gradyanlarÄ±nÄ± kullanarak **kanal aÄŸÄ±rlÄ±klarÄ±** Ã§Ä±karÄ±r ve Ä±sÄ± haritasÄ± Ã¼retir.\n\n### BileÅŸenler\n- `_apply_head_from_base_features(feats)`  \n  - `model.layers` iÃ§inde `base` katmanÄ±ndan **sonra gelen** katmanlarÄ± sÄ±rayla `feats` Ã¼zerine uygular.  \n  - `InputLayer` atlanÄ±r; `training=False` verilerek Dropout vb. deterministik Ã§alÄ±ÅŸÄ±r.  \n  - DÃ¶nen Ã§Ä±ktÄ±: `(1, num_classes)` (veya eÅŸdeÄŸeri).\n- `grad_cam_batch(x_imgs, class_idx=None, alpha=0.35)`  \n  - Her Ã¶rnek iÃ§in:  \n    1) `conv_out = base(x1, training=False)`  \n    2) `preds = _apply_head_from_base_features(conv_out)`  \n    3) Hedef skor (`score`):  \n       - `class_idx=None` â†’ **modelin tahmin ettiÄŸi sÄ±nÄ±f**  \n       - `class_idx=int/list[int]` â†’ **belirlenen sÄ±nÄ±f(lar)**  \n    4) `grads = âˆ‚score/âˆ‚conv_out` â†’ Kanal baÅŸÄ±na ortalama al (`weights`)  \n    5) `cam = ReLU(sum(weights * conv_out_channels))` â†’ [0,1] normalize  \n    6) Orijinal resme **Ä±sÄ± haritasÄ±nÄ±** `alpha` ile yarÄ± saydam bindir.\n  - DÃ¶nen Ã§Ä±ktÄ±: `(orig_uint8_img, heatmap_overlay_uint8)` listesi.\n\n### Parametreler & Ä°puÃ§larÄ±\n- `class_idx` : Hedef sÄ±nÄ±fÄ± kontrol etmek iÃ§in kullanÄ±lÄ±r; **yanlÄ±ÅŸ sÄ±nÄ±fa bakmayÄ±** Ã¶nlemek adÄ±na faydalÄ±dÄ±r.\n- `alpha` : IsÄ± haritasÄ± ÅŸeffaflÄ±ÄŸÄ±; 0.25â€“0.5 arasÄ± tipik.\n- Base/Head baÄŸÄ±mlÄ±lÄ±ÄŸÄ±: EÄŸer `grads is None` â†’ head zinciri base Ã§Ä±ktÄ±sÄ±na **baÄŸlÄ± deÄŸildir** (mimariyi kontrol edin).\n- GÃ¶rsel aralÄ±ÄŸÄ±: `_to_uint8_rgb` her tÃ¼rlÃ¼ `[âˆ’1,1]`, `[0,1]`, `[0,255]` giriÅŸini gÃ¼venli biÃ§imde `uint8 [0,255]`â€™e Ã§evirir.","metadata":{}},{"cell_type":"code","source":"def _apply_head_from_base_features(feats, model, base):\n    \"\"\"\n    feats: (1, Hc, Wc, C)  base(x) Ã§Ä±ktÄ±sÄ±\n    model: tam model (Input -> base -> GAP -> Dropout -> Dense)\n    base : model iÃ§indeki conv gÃ¶vde (Ã¶r. model.get_layer('efficientnetb0'))\n    \"\"\"\n    x = feats\n    take = False\n    for ly in model.layers:\n        if ly.name == base.name and not take:\n            take = True\n            continue\n        if not take:\n            continue\n        if isinstance(ly, tf.keras.layers.InputLayer):\n            continue\n        x = ly(x, training=False)\n    return x\n\ndef grad_cam_batch(x_imgs, class_idx=None, alpha=0.35):\n    outs = []\n    B = int(x_imgs.shape[0])\n\n    for b in range(B):\n        x1 = x_imgs[b:b+1]\n\n        with tf.GradientTape() as tape:\n            conv_out = base(x1, training=False)   # (1,Hc,Wc,C)\n            tape.watch(conv_out)\n\n            preds = _apply_head_from_base_features(conv_out, model, base)\n            if preds.shape.rank is None or preds.shape.rank > 2:\n                xgap = tf.reduce_mean(conv_out, axis=[1, 2])\n                drop_ly = None\n                dense_ly = None\n                \n                for ly in reversed(model.layers):\n                    if isinstance(ly, tf.keras.layers.Dense) and dense_ly is None:\n                        dense_ly = ly\n                    elif isinstance(ly, tf.keras.layers.Dropout) and drop_ly is None:\n                        drop_ly = ly\n                    if drop_ly is not None and dense_ly is not None:\n                        break\n                xhead = xgap\n                if drop_ly is not None:\n                    xhead = drop_ly(xhead, training=False)\n                if dense_ly is not None:\n                    preds = dense_ly(xhead, training=False)\n                else:\n                    raise RuntimeError(\"Head katmanlarÄ± bulunamadÄ±: Dense katmanÄ± sonda bekleniyordu.\")\n\n            # Hedef sÄ±nÄ±f\n            if class_idx is None:\n                target_id = tf.argmax(preds[0], axis=-1)   # sÄ±nÄ±f ekseni boyunca\n            else:\n                target_id = class_idx if isinstance(class_idx, int) else class_idx[b]\n                target_id = tf.convert_to_tensor(target_id)\n\n            score = preds[0, target_id]\n\n        grads = tape.gradient(score, conv_out)\n        if grads is None:\n            raise RuntimeError(\"Grad alÄ±namadÄ±: head zinciri base Ã§Ä±ktÄ±sÄ±na baÄŸlÄ± deÄŸil.\")\n\n        conv  = conv_out[0]                        \n        grad  = grads[0]                           \n        weights = tf.reduce_mean(grad, axis=(0,1), keepdims=True)\n        cam = tf.reduce_sum(weights * conv, axis=-1)  \n        cam = tf.nn.relu(cam).numpy()\n        cam = (cam - cam.min()) / (cam.max() - cam.min() + 1e-12)\n\n        # GÃ¶rselleÅŸtirme\n        img = _to_uint8_rgb(x_imgs[b])\n        heat = cv2.resize(cam.astype(np.float32), (img.shape[1], img.shape[0]))\n        heat = (255 * heat).astype(np.uint8)\n        heat = cv2.applyColorMap(heat, cv2.COLORMAP_JET)\n        heat = cv2.cvtColor(heat, cv2.COLOR_BGR2RGB)\n        vis  = cv2.addWeighted(heat, alpha, img, 1 - alpha, 0)\n        outs.append((img, vis))\n    return outs\n    \nfor xb, yb in test_ds.take(1):\n    k = min(5, xb.shape[0])\n    res_eigen = eigen_cam_batch(xb[:k], alpha=0.35)   # mevcut Ã§alÄ±ÅŸan\n    res_grad  = grad_cam_batch (xb[:k], alpha=0.35)   # yeni\n\n    for i in range(k):\n        img_e, vis_e = res_eigen[i]\n        img_g, vis_g = res_grad[i]\n        plt.figure(figsize=(9,3))\n        plt.subplot(1,3,1); plt.imshow(img_e); plt.axis('off'); plt.title('Input')\n        plt.subplot(1,3,2); plt.imshow(vis_e); plt.axis('off'); plt.title('Eigen-CAM')\n        plt.subplot(1,3,3); plt.imshow(vis_g); plt.axis('off'); plt.title('Grad-CAM')\n        plt.tight_layout(); plt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T21:10:46.570941Z","iopub.execute_input":"2025-09-25T21:10:46.571476Z","iopub.status.idle":"2025-09-25T21:10:52.169837Z","shell.execute_reply.started":"2025-09-25T21:10:46.571453Z","shell.execute_reply":"2025-09-25T21:10:52.169092Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 16) CAM GÃ¶rsellerinden SeÃ§ki (2 DoÄŸru + 2 YanlÄ±ÅŸ)\n\nBu hÃ¼cre, test kÃ¼mesinden **doÄŸru sÄ±nÄ±flandÄ±rÄ±lmÄ±ÅŸ** ve **yanlÄ±ÅŸ sÄ±nÄ±flandÄ±rÄ±lmÄ±ÅŸ** Ã¶rneklerden seÃ§erek **Eigen-CAM / Grad-CAM** bindirmelerini yan yana gÃ¶sterir.\n\n**Fonksiyon**\n- `show_cam_samples_from_ds(test_ds, y_true_vec, y_pred_vec, classes, eigen_cam_fn, grad_cam_fn, alpha=0.35, k_correct=2, k_wrong=2)`\n  - **Toplama**: `test_ds` iÃ§indeki tÃ¼m gÃ¶rÃ¼ntÃ¼ler belleÄŸe alÄ±nÄ±r (`x_all`).  \n  - **SeÃ§im**:  \n    - `correct_idx`: `y_true_vec == y_pred_vec` (doÄŸru tahminler)  \n    - `wrong_idx`  : `y_true_vec != y_pred_vec` (yanlÄ±ÅŸ tahminler)  \n    - Ä°lk `k_correct` ve `k_wrong` Ã¶rnek alÄ±nÄ±r.  \n  - **CAM Ã¼retimi**:  \n    - `eigen_cam_fn(xb_tf, alpha)` â†’ `(img, vis)`  \n    - `grad_cam_fn(xb_tf, alpha)`  â†’ `(img, vis)`  \n    - Her Ã¶rnek iÃ§in Input + (varsa) Eigen-CAM + Grad-CAM sÃ¼tunlarÄ± Ã§izilir.\n  - **BaÅŸlÄ±klar**: `T:{true_c} / P:{pred_c}` ile gerÃ§ek/tahmin edilen sÄ±nÄ±flar gÃ¶sterilir.\n\n**Ã–nemli Notlar**\n- Fonksiyon, CAM iÃ§in `tf.float32` tensÃ¶rÃ¼ne dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r (**`xb_tf`**).  \n- GÃ¶rÃ¼ntÃ¼ Ã§iziminde `plt.imshow(np.uint8(xb[0]))` kullanÄ±lÄ±yor.  \n  - EÄŸer pipelineâ€™da gÃ¶rÃ¼ntÃ¼ler **[-1, 1]** aralÄ±ÄŸÄ±ndaysa, orijinal inputâ€™u doÄŸru gÃ¶rmek iÃ§in **Ã¶nce** `[0,255]` aralÄ±ÄŸÄ±na Ã¶lÃ§eklemek gerekebilir (aksi halde soluk/bozuk gÃ¶rÃ¼nebilir).  \n  - CAM bindirmeleri (`vis`) zaten `uint8` ve doÄŸru aralÄ±ktadÄ±r (Eigen-CAM/Grad-CAM iÃ§inde `_to_uint8_rgb` kullanÄ±lÄ±yor).\n","metadata":{}},{"cell_type":"code","source":"\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nimport tensorflow as tf\n\ndef show_cam_samples_from_ds(test_ds, y_true_vec, y_pred_vec, classes,\n                             eigen_cam_fn=None, grad_cam_fn=None,\n                             alpha=0.35, k_correct=2, k_wrong=2):\n    \"\"\"\n    test_ds     : tf.data.Dataset -> (images, labels)  [labels one-hot olabilir]\n    y_true_vec  : 1D numpy array, gerÃ§ek sÄ±nÄ±f indeksleri\n    y_pred_vec  : 1D numpy array, tahmin sÄ±nÄ±f indeksleri\n    classes     : sÄ±nÄ±f isim listesi\n    \"\"\"\n   \n    x_batches = []\n    for x, _ in test_ds:\n        x_batches.append(x.numpy())\n    x_all = np.concatenate(x_batches, axis=0)\n\n    correct_idx = np.where(y_true_vec == y_pred_vec)[0]\n    wrong_idx   = np.where(y_true_vec != y_pred_vec)[0]\n\n    pick_correct = correct_idx[:k_correct]\n    pick_wrong   = wrong_idx[:k_wrong]\n    chosen = list(pick_correct) + list(pick_wrong)\n\n    for i in chosen:\n        xb = x_all[i:i+1]\n        row_imgs = []\n\n        if eigen_cam_fn is not None:\n            xb_tf = tf.convert_to_tensor(xb, dtype=tf.float32)  \n            img_e, vis_e = eigen_cam_fn(xb_tf, alpha=alpha)[0]\n            row_imgs.append((\"Eigen-CAM\", vis_e))\n        \n        if grad_cam_fn is not None:\n            xb_tf = tf.convert_to_tensor(xb, dtype=tf.float32)  \n            img_g, vis_g = grad_cam_fn(xb_tf, alpha=alpha)[0]\n            row_imgs.append((\"Grad-CAM\", vis_g))\n\n        cols = len(row_imgs) + 1\n        plt.figure(figsize=(4*cols, 4))\n        # Orijinal gÃ¶rÃ¼ntÃ¼\n        plt.subplot(1, cols, 1)\n        plt.imshow(np.uint8(xb[0]))\n        plt.axis('off')\n        true_c = classes[int(y_true_vec[i])]\n        pred_c = classes[int(y_pred_vec[i])]\n        plt.title(f\"Input\\nT:{true_c} / P:{pred_c}\")\n\n        for j, (name, overlay) in enumerate(row_imgs, start=2):\n            plt.subplot(1, cols, j)\n            plt.imshow(overlay)\n            plt.axis('off')\n            plt.title(name)\n\n        plt.tight_layout()\n        plt.show()\n\nshow_cam_samples_from_ds(\n    test_ds,\n    y_true_vec,\n    y_pred_vec,\n    classes,\n    eigen_cam_fn=eigen_cam_batch,\n    grad_cam_fn=grad_cam_batch,\n    alpha=0.35\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T21:10:57.530297Z","iopub.execute_input":"2025-09-25T21:10:57.530859Z","iopub.status.idle":"2025-09-25T21:11:03.276727Z","shell.execute_reply.started":"2025-09-25T21:10:57.530837Z","shell.execute_reply":"2025-09-25T21:11:03.276041Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 17) Tek GÃ¶rselden Tahmin (predict_file)\n\nBu fonksiyon, **kaydedilmiÅŸ modeli kullanarak tek bir resim iÃ§in sÄ±nÄ±f tahmini yapar**.\n\n**AdÄ±mlar**\n- `Image.open(img_path).convert(\"RGB\").resize((IMG_SIZE, IMG_SIZE))`  \n  â†’ Resmi RGB formatÄ±na Ã§evirip modelin beklediÄŸi boyuta getirir.\n- `np.array(img).astype(\"float32\")`  \n  â†’ GÃ¶rÃ¼ntÃ¼yÃ¼ sayÄ±sal tensÃ¶re dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r.\n- `preprocess_input(x)`  \n  â†’ Piksel deÄŸerlerini **[-1,1]** aralÄ±ÄŸÄ±na normalize eder.\n- `model.predict(x[None, ...])`  \n  â†’ Tek resmi batch boyutuna geniÅŸleterek tahmin eder.\n- `argsort()[::-1][:topk]`  \n  â†’ En yÃ¼ksek olasÄ±lÄ±klÄ± **ilk `topk` sÄ±nÄ±fÄ±** seÃ§er (varsayÄ±lan `topk=3`).\n","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.applications.efficientnet import preprocess_input\nfrom PIL import Image\nimport numpy as np, tensorflow as tf\n\ndef predict_file(img_path, topk=3):\n    img = Image.open(img_path).convert(\"RGB\").resize((IMG_SIZE, IMG_SIZE))\n    x   = np.array(img).astype(\"float32\")\n    x   = preprocess_input(x)                      # [-1,1]\n    pr  = model.predict(x[None, ...], verbose=0)[0]\n    idx = pr.argsort()[::-1][:topk]\n    return [(classes[i], float(pr[i])) for i in idx]\n\npreds = predict_file(\"/kaggle/input/flowers-recognition/flowers/rose/10090824183_d02c613f10_m.jpg\")\nfor cls, prob in preds:\n    print(f\"{cls}: {prob:.2%}\")\n   \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T21:11:10.021574Z","iopub.execute_input":"2025-09-25T21:11:10.021818Z","iopub.status.idle":"2025-09-25T21:11:17.295247Z","shell.execute_reply.started":"2025-09-25T21:11:10.021801Z","shell.execute_reply":"2025-09-25T21:11:17.294565Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 18) Test-Time Augmentation (TTA) ile Tahmin\n\nBu adÄ±m, **tahmin sÄ±rasÄ±nda veri artÄ±rma** (Ã¶rn. yatay Ã§evirme) uygulayarak modelin genelleme gÃ¼cÃ¼nÃ¼ artÄ±rÄ±r ve **daha kararlÄ± sonuÃ§lar** elde eder.\n\n### Fonksiyon\n- `predict_with_tta(x_batch, n=4)`\n  - `x_batch` : Ã–nceden `preprocess_input` uygulanmÄ±ÅŸ gÃ¶rÃ¼ntÃ¼ batchâ€™i.\n  - `n` : AynÄ± batch iÃ§in kaÃ§ farklÄ± gÃ¶rÃ¼nÃ¼m (augmentation) ile tahmin alÄ±nacaÄŸÄ±.\n  - DÃ¶ngÃ¼:\n    - Ã‡ift turlar â†’ orijinal gÃ¶rÃ¼ntÃ¼  \n    - Tek turlar â†’ **yatay Ã§evrilmiÅŸ** gÃ¶rÃ¼ntÃ¼ (`tf.image.flip_left_right`).\n    - `model.predict` Ã§Ä±ktÄ±larÄ± `outs` listesine eklenir.\n  - `np.mean(outs, axis=0)` â†’ TÃ¼m tahminlerin ortalamasÄ± alÄ±nÄ±r (**olasÄ±lÄ±klarÄ± yumuÅŸatÄ±r**).","metadata":{}},{"cell_type":"code","source":"def predict_with_tta(x_batch, n=4):  \n    outs = []\n    for t in range(n):\n        xb = x_batch\n        if t % 2 == 1:\n            xb = tf.image.flip_left_right(xb)\n        pr = model.predict(xb, verbose=0)\n        outs.append(pr)\n    return np.mean(outs, axis=0)\n\n\navg_probs = np.vstack([predict_with_tta(xb) for xb, _ in test_ds])\ny_pred = avg_probs.argmax(1)\ntta_acc = (y_true_vec == y_pred).mean()\n\n\nidx = 0   # test setindeki ilk Ã¶rnek\nprint(\"GerÃ§ek sÄ±nÄ±f:\", classes[y_true_vec[idx]])\nprint(\"Tahmin edilen:\", classes[y_pred[idx]])\nprint(\"Ortalama olasÄ±lÄ±klar:\", avg_probs[idx])\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T21:11:22.295643Z","iopub.execute_input":"2025-09-25T21:11:22.295905Z","iopub.status.idle":"2025-09-25T21:11:41.563547Z","shell.execute_reply.started":"2025-09-25T21:11:22.295887Z","shell.execute_reply":"2025-09-25T21:11:41.562863Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 19) Bottleneck (Ã–nceden Ã‡Ä±karÄ±lmÄ±ÅŸ Ã–zellik) YaklaÅŸÄ±mÄ± â€“ HÄ±zlÄ± Arama\n\nBu blok, EfficientNetB0â€™un konvolÃ¼syonel kÄ±smÄ±nÄ± **donuk (frozen) Ã¶zellik Ã§Ä±karÄ±cÄ±** olarak kullanÄ±p, eÄŸitim verisini **bir kez ileri geÃ§irerek** (forward) **bottleneck** Ã¶zelliklerini RAMâ€™e (veya dosyaya) alÄ±r. AmaÃ§: **deneme/arama hÄ±zÄ±nÄ±** bÃ¼yÃ¼k Ã¶lÃ§Ã¼de artÄ±rmak.\n\n**Ne yapar?**\n- `IMG_SIZE` hem `int` hem `(H,W)` gelirse uyumludur.\n- `feature_extractor`: `EfficientNetB0(include_top=False)` + `GlobalAveragePooling2D`  \n  â†’ Sadece **Ã¶zellik** Ã¼retir, **eÄŸitilmez** (`trainable=False`).\n- `subset_frac`: HÄ±zlÄ± denemeler iÃ§in eÄŸitim/validasyonun bir **alt kÄ±smÄ±nÄ±** kullanÄ±r (Ã¶rn. 0.3).\n- `ds_to_features(ds)`:  \n  - Her batchâ€™i `feature_extractor` iÃ§inden geÃ§irip `(B, C)` boyutlu Ã¶zellikleri toplar.  \n  - Etiketleri de toplar; **one-hot** ise **sparse** sÄ±nÄ±f indeksine Ã§evirir.  \n- `np.savez(...)`: Ã–zellikleri ve etiketleri diske kaydeder (isteÄŸe baÄŸlÄ±).\n\n**Ã‡Ä±ktÄ±lar**\n- `Xtr, ytr`: EÄŸitim Ã¶zellikleri ve etiketler  \n- `Xva, yva`: Validasyon Ã¶zellikleri ve etiketler  \n- Ã–rnek: `Train feats: (N_train, C)  Val feats: (N_val, C)`\n\n**Neden faydalÄ±?**\n- Ãœstte kÃ¼Ã§Ã¼k bir **head** (Dense + Dropout vb.) eÄŸiterek **Ã§ok hÄ±zlÄ±** model aramasÄ± (LR, dropout, hidden size...) yapabilirsiniz.\n- AÄŸÄ±r konvolÃ¼syon kÄ±smÄ± her seferinde Ã§alÄ±ÅŸmadÄ±ÄŸÄ±ndan **GPU/CPU sÃ¼resi** kÄ±salÄ±r.\n\n\n> Ã–zet: Bottleneck yaklaÅŸÄ±mÄ±, **hÄ±zlÄ± prototipleme ve hiperparametre aramasÄ±** iÃ§in idealdir; sonrasÄ±nda dilerseniz tam eÄŸitim (end-to-end veya kademeli fine-tuning) ile sonuÃ§larÄ± rafine edebilirsiniz.\n","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf, numpy as np, os, pandas as pd\nfrom tensorflow.keras import layers, models\n\n\nif isinstance(IMG_SIZE, tuple):\n    H, W = IMG_SIZE\nelse:\n    H = W = int(IMG_SIZE)\n\nnum_classes = len(classes)\ninp = tf.keras.Input(shape=(H, W, 3))\nb0  = tf.keras.applications.EfficientNetB0(include_top=False, weights=\"imagenet\")(inp, training=False)\ngap = layers.GlobalAveragePooling2D()(b0)\nfeature_extractor = models.Model(inp, gap, name=\"b0_gap\")\nfeature_extractor.trainable = False\n\nsubset_frac = 1.0  \ndef take_fraction(ds, frac):\n    if frac >= 1.0: return ds\n    total = 0\n    for _ in ds: total += 1\n    take_n = max(1, int(total*frac))\n    return ds.take(take_n)\n\ntrain_search = take_fraction(train_ds, subset_frac)\nval_search   = take_fraction(val_ds,   subset_frac)\n\ndef ds_to_features(ds):\n    X, y = [], []\n    for xb, yb in ds:\n        feats = feature_extractor(xb, training=False).numpy()  # (B, C)\n        X.append(feats)\n        y.append(yb.numpy())\n    X = np.concatenate(X, axis=0)\n    y = np.concatenate(y, axis=0)\n\n    if y.ndim == 2 and y.shape[1] == num_classes:\n        y = y.argmax(axis=1)\n    return X, y.astype(\"int32\")\n\nXtr, ytr = ds_to_features(train_search)\nXva, yva = ds_to_features(val_search)\n\nprint(\"Train feats:\", Xtr.shape, \"Val feats:\", Xva.shape)\nnp.savez(\"/kaggle/working/bottlenecks.npz\", Xtr=Xtr, ytr=ytr, Xva=Xva, yva=yva)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T21:11:47.234758Z","iopub.execute_input":"2025-09-25T21:11:47.235546Z","iopub.status.idle":"2025-09-25T21:12:22.846779Z","shell.execute_reply.started":"2025-09-25T21:11:47.235520Z","shell.execute_reply":"2025-09-25T21:12:22.846103Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 20) HÄ±zlÄ± Hiperparametre AramasÄ± (Optimizer + Batch Size Dahil)\n\nBu hÃ¼cre, **bottleneck Ã¶zellikleri** Ã¼zerinde yalnÄ±zca **Ã¼st sÄ±nÄ±flandÄ±rÄ±cÄ± (head)** iÃ§in  \nhÄ±zlÄ± ve geniÅŸ kapsamlÄ± bir **hiperparametre aramasÄ±** yapar.  \nÃ–nceki bloklarda oluÅŸturulan `Xtr, ytr, Xva, yva` verilerini kullanÄ±r.\n\n### AdÄ±mlar\n\n1. **Bottleneck Ã–zellik Ã‡Ä±karÄ±mÄ± (subset_frac=0.5)**  \n   - EÄŸitim ve doÄŸrulama verilerinin %50â€™si alÄ±nÄ±r.  \n   - EfficientNetB0 gÃ¶vdesi **donuk** bÄ±rakÄ±lÄ±r.  \n   - BÃ¶ylece veri boyutu yarÄ±ya iner ve deneyler Ã§ok daha hÄ±zlÄ± tamamlanÄ±r.\n\n2. **Head Modeli Kurulumu ve EÄŸitimi**  \n   - Mimari: `Dense(dense_units, relu)` (opsiyonel) â†’ `Dropout(drop)` â†’ `Dense(num_classes, softmax)`.\n   - KayÄ±p fonksiyonu: `SparseCategoricalCrossentropy`.  \n   - Metrik: `accuracy`.\n   - Erken durdurma (`EarlyStopping`) ile aÅŸÄ±rÄ± eÄŸitim engellenir.\n\n3. **Grid AramasÄ±**  \n   - Ã–ÄŸrenme oranÄ± (`lr`): **1e-3**, **5e-4**  \n   - Dropout (`drop`): **0.3**, **0.5**  \n   - Gizli katman nÃ¶ron sayÄ±sÄ± (`dense_units`): **0**, **128**  \n   - Optimizasyon algoritmasÄ± (`optimizer`): **adam**, **rmsprop**  \n   - Batch size (`batch_size`): **32**, **64**  \n   - Toplam **24 kombinasyon** denenir. \n\n4. **Raporlama ve KayÄ±t**  \n   - TÃ¼m denemeler `df` DataFrameâ€™inde saklanÄ±r, **val_acc**â€™e gÃ¶re sÄ±ralanÄ±r.\n   - SonuÃ§lar `/kaggle/working/results_hparam_search.csv` dosyasÄ±na kaydedilir.\n   - En iyi kombinasyon ve en yÃ¼ksek `val_acc` konsola yazdÄ±rÄ±lÄ±r.\n","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf, numpy as np, pandas as pd\nfrom tensorflow.keras import layers, models, optimizers, losses, callbacks\n\n\nif isinstance(IMG_SIZE, tuple):\n    H, W = IMG_SIZE\nelse:\n    H = W = int(IMG_SIZE)\n\nnum_classes = len(classes)\ninp = tf.keras.Input(shape=(H, W, 3))\nb0  = tf.keras.applications.EfficientNetB0(include_top=False, weights=\"imagenet\")(inp, training=False)\ngap = layers.GlobalAveragePooling2D()(b0)\nfeature_extractor = models.Model(inp, gap, name=\"b0_gap\")\nfeature_extractor.trainable = False\n\n\nsubset_frac = 0.5\ndef take_fraction(ds, frac: float):\n    if frac >= 1.0:\n        return ds\n    total = 0\n    for _ in ds:\n        total += 1\n    take_n = max(1, int(total * frac))\n    return ds.take(take_n)\n\ntrain_search = take_fraction(train_ds, subset_frac)\nval_search   = take_fraction(val_ds,   subset_frac)\n\ndef ds_to_features(ds):\n    X, y = [], []\n    for xb, yb in ds:\n        feats = feature_extractor(xb, training=False).numpy() \n        X.append(feats)\n        y.append(yb.numpy())\n    X = np.concatenate(X, axis=0)\n    y = np.concatenate(y, axis=0)\n    if y.ndim == 2 and y.shape[1] == num_classes: \n        y = y.argmax(axis=1)\n    return X, y.astype(\"int32\")\n\nXtr, ytr = ds_to_features(train_search)\nXva, yva = ds_to_features(val_search)\nprint(f\"[HÄ±zlÄ± Mod] Train feats: {Xtr.shape}, Val feats: {Xva.shape} (subset_frac={subset_frac})\")\nearly_stop = callbacks.EarlyStopping(monitor=\"val_accuracy\", patience=2, restore_best_weights=True)\n\ndef make_optimizer(name: str, lr: float):\n    name = (name or \"adam\").lower()\n    if name == \"adam\":\n        return optimizers.Adam(learning_rate=lr)\n    if name == \"rmsprop\":\n        return optimizers.RMSprop(learning_rate=lr)\n    if name == \"sgd\":\n        return optimizers.SGD(learning_rate=lr, momentum=0.9, nesterov=True)\n    raise ValueError(f\"Bilinmeyen optimizer: {name}\")\n\ndef quick_try_head(\n    lr=1e-3,\n    drop=0.4,\n    dense_units=0,\n    optimizer_name=\"adam\",\n    batch_size=64,\n    epochs=8,        \n    verbose=0,\n):\n    inputs = layers.Input(shape=(Xtr.shape[1],))\n    x = inputs\n    if dense_units > 0:\n        x = layers.Dense(dense_units, activation=\"relu\")(x)\n        x = layers.Dropout(drop)(x)\n    else:\n        x = layers.Dropout(drop)(x)\n    outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n\n    m = models.Model(inputs, outputs)\n    m.compile(optimizer=make_optimizer(optimizer_name, lr),\n              loss=losses.SparseCategoricalCrossentropy(),\n              metrics=[\"accuracy\"])\n\n    h = m.fit(\n        Xtr, ytr,\n        validation_data=(Xva, yva),\n        epochs=epochs,\n        batch_size=batch_size,\n        callbacks=[early_stop],\n        verbose=verbose,\n    )\n    return float(max(h.history[\"val_accuracy\"])), m\n\n\ngrid_lr   = [1e-3, 5e-4]\ngrid_drop = [0.3, 0.5]\ngrid_dense= [0, 128]\ngrid_opt  = [\"adam\", \"rmsprop\"]      \ngrid_bs   = [32, 64]\n\ntries = []\nbest_cfg, best_acc, best_model = None, -1.0, None\n\nfor lr in grid_lr:\n    for drop in grid_drop:\n        for dense in grid_dense:\n            for opt_name in grid_opt:\n                for bs in grid_bs:\n                    acc, model_head = quick_try_head(\n                        lr=lr,\n                        drop=drop,\n                        dense_units=dense,\n                        optimizer_name=opt_name,\n                        batch_size=bs,\n                        epochs=8,   \n                        verbose=0,\n                    )\n                    tries.append((lr, drop, dense, opt_name, bs, acc))\n                    if acc > best_acc:\n                        best_cfg, best_acc, best_model = (lr, drop, dense, opt_name, bs), acc, model_head\n\ncols = [\"lr\", \"dropout\", \"dense_units\", \"optimizer\", \"batch_size\", \"val_acc\"]\ndf = pd.DataFrame(tries, columns=cols).sort_values(\"val_acc\", ascending=False)\ndf.to_csv(\"/kaggle/working/results_hparam_search.csv\", index=False)\nprint(\"Tablo kaydedildi\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T21:14:55.305533Z","iopub.execute_input":"2025-09-25T21:14:55.305775Z","iopub.status.idle":"2025-09-25T21:17:02.036381Z","shell.execute_reply.started":"2025-09-25T21:14:55.305760Z","shell.execute_reply":"2025-09-25T21:17:02.035645Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 21) Hiperparametre Arama SonuÃ§larÄ±nÄ±n Tabloya DÃ¶kÃ¼lmesi\n\nBu hÃ¼cre, `tries` listesindeki tÃ¼m denemeleri **DataFrame**â€™e Ã§evirir, en iyi doÄŸrulamaya gÃ¶re sÄ±ralar ve hem **CSV** hem **Markdown** biÃ§iminde Ã§Ä±ktÄ±lar.\n\n**AdÄ±mlar**\n- `tries` iÃ§eriÄŸine gÃ¶re sÃ¼tun adlarÄ±nÄ± otomatik belirler:  \n  - 3 elemanlÄ± tuple â†’ `[\"learning_rate\", \"dropout\", \"val_acc\"]`  \n  - 6 elemanlÄ± tuple â†’ `[\"lr\", \"dropout\", \"dense_units\", \"optimizer\", \"batch_size\", \"val_acc\"]`\n- `df.sort_values(\"val_acc\", ascending=False)` â†’ En yÃ¼ksek doÄŸruluk Ã¼ste alÄ±nÄ±r.\n- `df.to_csv(\"/kaggle/working/results_hparam_search.csv\")` â†’ SonuÃ§lar **CSV** dosyasÄ± olarak kaydedilir.\n- `df.to_markdown()` â†’ Notebook Ã§Ä±ktÄ±sÄ±nda **Markdown tablosu** halinde gÃ¶sterir.  \n  - `tabulate` yÃ¼klÃ¼ deÄŸilse fallback olarak `tabulate()` ile basit biÃ§imde basar.\n","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\nif not tries:\n    raise ValueError(\"tries boÅŸ gÃ¶rÃ¼nÃ¼yor.\")\n\nn = len(tries[0])\nif n == 3:\n    cols = [\"learning_rate\", \"dropout\", \"val_acc\"]\nelif n == 6:\n    cols = [\"lr\", \"dropout\", \"dense_units\", \"optimizer\", \"batch_size\", \"val_acc\"]\nelse:\n    cols = [f\"col{i}\" for i in range(n)]  \ndf = pd.DataFrame(tries, columns=cols)\ndf = df.sort_values(\"val_acc\", ascending=False)\ndf.to_csv(\"/kaggle/working/results_hparam_search.csv\", index=False)\n\ntry:\n    print(df.to_markdown(index=False))\nexcept Exception:\n    from tabulate import tabulate \n    print(tabulate(df, headers='keys', tablefmt='github', showindex=False))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T21:18:58.974341Z","iopub.execute_input":"2025-09-25T21:18:58.975007Z","iopub.status.idle":"2025-09-25T21:18:59.015329Z","shell.execute_reply.started":"2025-09-25T21:18:58.974982Z","shell.execute_reply":"2025-09-25T21:18:59.014701Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 22) En Ä°yi Hiperparametre Seti ve KÄ±sa GerekÃ§e\n\nBu hÃ¼cre, hiperparametre aramasÄ±nda elde edilen en iyi kombinasyonu ve kÄ±sa bir seÃ§im gerekÃ§esini otomatik olarak raporlar.\n\n**AdÄ±mlar**\n- `best_idx = df[\"val_acc\"].idxmax()` â†’ En yÃ¼ksek doÄŸrulama doÄŸruluÄŸuna sahip satÄ±rÄ±n indeksini bulur.\n- `best = df.loc[best_idx].to_dict()` â†’ Bu satÄ±rdaki tÃ¼m hiperparametreleri (Ã¶r. lr, dropout, dense_unitsâ€¦) sÃ¶zlÃ¼k olarak alÄ±r.\n- `print` dÃ¶ngÃ¼sÃ¼ ile her hiperparametre ve deÄŸeri satÄ±r satÄ±r gÃ¶sterir.\n\n**GerekÃ§e MantÄ±ÄŸÄ±**\n- En yÃ¼ksek `val_acc` deÄŸeri temel alÄ±nÄ±r.\n- Ä°lk 3 sonucu inceler; eÄŸer 1. ve 2. skorlar **Ã§ok yakÄ±nsa (<0.005 fark)**:\n  - Dropout veya L2 gibi **dÃ¼zenlileÅŸtirme** parametreleri karÅŸÄ±laÅŸtÄ±rÄ±lÄ±r.\n  - Daha yÃ¼ksek dÃ¼zenlileÅŸtirme varsa **daha stabil ve genelleÅŸtirilebilir** yapÄ± vurgulanÄ±r.\n- Fark belirgin ise: â€œAlternatiflere gÃ¶re belirgin ÅŸekilde daha yÃ¼ksek doÄŸrulama baÅŸarÄ±mÄ±â€ notu eklenir.\n","metadata":{}},{"cell_type":"code","source":"\nimport numpy as np\n\nassert \"val_acc\" in df.columns, \"df iÃ§inde 'val_acc' sÃ¼tunu yok!\"\nbest_idx = df[\"val_acc\"].idxmax()\nbest = df.loc[best_idx].to_dict()\n\nprint(\"SeÃ§ilen en iyi set:\")\nfor k, v in best.items():\n    print(f\" - {k}: {v}\")\n\ntop3 = df.sort_values(\"val_acc\", ascending=False).head(3).reset_index(drop=True)\nmsg = [f\"\\nGerekÃ§e:\",\n       f\"- En yÃ¼ksek doÄŸrulama baÅŸarÄ±mÄ±: {top3.loc[0,'val_acc']:.4f}.\"]\n\nif len(top3) > 1 and (top3.loc[0,\"val_acc\"] - top3.loc[1,\"val_acc\"]) < 0.005:\n    hint_cols = [c for c in df.columns if (\"dropout\" in c.lower()) or (\"l2\" in c.lower())]\n    if hint_cols:\n        better_reg = []\n        for c in hint_cols:\n            v0 = top3.loc[0, c]\n            v1 = top3.loc[1, c]\n            if isinstance(v0, (int,float)) and isinstance(v1, (int,float)) and v0>=v1:\n                better_reg.append(f\"{c}={v0}\")\n        if better_reg:\n            msg.append(f\"- YakÄ±n rakibe kÄ±yasla daha gÃ¼Ã§lÃ¼ dÃ¼zenlileÅŸtirme ({', '.join(better_reg)}) iÃ§eriyor.\")\n    msg.append(\"- Skorlar Ã§ok yakÄ±n olduÄŸu iÃ§in daha **stabil** ve **genelleÅŸtirilebilir** yapÄ± tercih edildi.\")\nelse:\n    msg.append(\"- Alternatiflere gÃ¶re belirgin ÅŸekilde daha yÃ¼ksek doÄŸrulama baÅŸarÄ±mÄ±.\")\n\nprint(\"\\n\".join(msg))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T21:19:04.267575Z","iopub.execute_input":"2025-09-25T21:19:04.268288Z","iopub.status.idle":"2025-09-25T21:19:04.277874Z","shell.execute_reply.started":"2025-09-25T21:19:04.268263Z","shell.execute_reply":"2025-09-25T21:19:04.277164Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 23) YanlÄ±ÅŸ SÄ±nÄ±flandÄ±rÄ±lan Ã–rnekleri GÃ¶rselleÅŸtirme\n\nBu hÃ¼cre, **test kÃ¼mesinde modelin yanÄ±ldÄ±ÄŸÄ± ilk 15 Ã¶rneÄŸi** doÄŸru/gÃ¼venli bir gÃ¶rÃ¼ntÃ¼ Ã¶lÃ§eklemesiyle Ã§izip kaydeder.\n\n**Ne yapÄ±yor?**\n- `to_uint8_rgb(x)`  \n  - GÃ¶rÃ¼ntÃ¼yÃ¼ olasÄ± aralÄ±klardan (`[-1,1]`, `[0,1]`, `[0,255]`) **gÃ¼venle** `uint8 [0,255]` aralÄ±ÄŸÄ±na Ã§evirir.  \n  - CAM gÃ¶rselleriyle tutarlÄ± ve â€œdoÄŸal renkliâ€ gÃ¶rÃ¼ntÃ¼ sunar.\n- `y_true` / `y_pred`  \n  - Test kÃ¼mesinden **gerÃ§ek etiketleri** (one-hotâ€™tan `argmax`) ve **tahminleri** Ã¼retir.  \n  - `mis_idx` ile **yanlÄ±ÅŸ tahmin edilen** indeksler bulunur.\n- GÃ¶rsellerin derlenmesi  \n  - `test_ds` iÃ§indeki tÃ¼m batchâ€™lerdeki gÃ¶rÃ¼ntÃ¼ler `to_uint8_rgb` ile normalize edilip `test_images` listesine eklenir.\n- Ã‡izim ve kayÄ±t  \n  - `matplotlib` ile 3Ã—5 dÃ¼zeninde **ilk 15 yanlÄ±ÅŸ Ã¶rnek** Ã§izilir.  \n  - BaÅŸlÄ±k: `T:{gerÃ§ek sÄ±nÄ±f} / P:{tahmin edilen sÄ±nÄ±f}`  \n  - Dosya kaydÄ±: `/kaggle/working/misclassified_examples.png`\n\n**Neden Ã¶nemli?**\n- Modelin **hangi sÄ±nÄ±flarda ve hangi tÃ¼r gÃ¶rsellerde yanÄ±ldÄ±ÄŸÄ±** hÄ±zla gÃ¶rÃ¼lÃ¼r.  \n- KarÄ±ÅŸan sÄ±nÄ±flarÄ± inceleyip **augmentation** stratejisi, sÄ±nÄ±f aÄŸÄ±rlÄ±klarÄ± veya veri kalitesi hakkÄ±nda iyileÅŸtirme kararlarÄ± alabilirsiniz.\n","metadata":{}},{"cell_type":"code","source":"import numpy as np, matplotlib.pyplot as plt\n\ndef to_uint8_rgb(x):\n    \"\"\"\n    x: np.ndarray or tf.Tensor, shape (H,W,3)\n       OlasÄ± aralÄ±klar: [-1,1] ya da [0,1] ya da [0,255]\n    return: np.uint8 in [0,255]\n    \"\"\"\n    if hasattr(x, \"numpy\"):\n        x = x.numpy()\n    x = x.astype(np.float32)\n    vmin, vmax = x.min(), x.max()\n    if vmax <= 1.0 and vmin >= -1.0:   # [-1,1] veya [0,1]\n        if vmin < 0:                   # [-1,1]\n            x = (x + 1.0) * 127.5\n        else:                          # [0,1]\n            x = x * 255.0\n    x = np.clip(x, 0, 255).astype(np.uint8)\n    return x\n\ny_true_batches = []\nfor _, y in test_ds:\n    y_true_batches.append(np.argmax(y.numpy(), axis=1))\ny_true = np.concatenate(y_true_batches, axis=0)\ny_pred_probs = model.predict(test_ds, verbose=0)\ny_pred = np.argmax(y_pred_probs, axis=1)\nmis_idx = np.where(y_true != y_pred)[0]\ntest_images = []\nfor xb, _ in test_ds:\n    imgs = np.stack([to_uint8_rgb(im) for im in xb]) \n    test_images.extend(imgs)\n\nfig, axes = plt.subplots(3, 5, figsize=(12, 7))\nfor ax, i in zip(axes.ravel(), mis_idx[:15]):\n    ax.imshow(test_images[i])\n    ax.set_title(f\"T:{classes[y_true[i]]}\\nP:{classes[y_pred[i]]}\")\n    ax.axis('off')\nplt.tight_layout()\nplt.savefig(\"/kaggle/working/misclassified_examples.png\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T21:19:10.391959Z","iopub.execute_input":"2025-09-25T21:19:10.392235Z","iopub.status.idle":"2025-09-25T21:19:14.336535Z","shell.execute_reply.started":"2025-09-25T21:19:10.392217Z","shell.execute_reply":"2025-09-25T21:19:14.335584Z"}},"outputs":[],"execution_count":null}]}